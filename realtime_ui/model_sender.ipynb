{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "sys.path.append(\"./protos\")\n",
    "\n",
    "import grpc\n",
    "import messaging_pb2\n",
    "import messaging_pb2_grpc\n",
    "\n",
    "class ImageProcessingLayer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim=(1000, 1000),\n",
    "        mock=True,\n",
    "        mock_image_path=None,\n",
    "        mock_num_samples=10,\n",
    "        mock_wait_time=1,\n",
    "        mock_corner_gps_coords=None,\n",
    "    ):\n",
    "        self.mock = mock\n",
    "\n",
    "        if not mock:\n",
    "            return\n",
    "\n",
    "        self.mock_wait_time = mock_wait_time\n",
    "\n",
    "        if mock_image_path is None:\n",
    "            # mock_image_path = \"data/demo.jpg\"\n",
    "            mock_image_path = \"../data/demo.jpg\"\n",
    "\n",
    "        self._mock_img_full = np.asarray(Image.open(mock_image_path))[:, :, :3]\n",
    "\n",
    "        self._output_dim = output_dim\n",
    "        diag_len = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "        self._gcps_pixels = self._generate_random_gcps(\n",
    "            self._mock_img_full, mock_num_samples, padding=(diag_len, diag_len)\n",
    "        )\n",
    "\n",
    "        self._mock_corner_gps_coords = mock_corner_gps_coords\n",
    "        self._pixel_to_gps_transform = self._dataset_pixel_to_gps_transform(\n",
    "            self._mock_corner_gps_coords\n",
    "        )\n",
    "\n",
    "        self._path_pixels = self._build_path_pixels(self._gcps_pixels)\n",
    "\n",
    "    def _generate_random_gcps(self, img, num_samples, padding=(0, 0)):\n",
    "        return np.random.randint(\n",
    "            padding,\n",
    "            high=(\n",
    "                img.shape[1] - padding[0] - 10,\n",
    "                img.shape[0] - padding[1] - 10,\n",
    "            ),\n",
    "            size=(num_samples, 2),\n",
    "        )\n",
    "\n",
    "    def _build_path_pixels(self, gcps):\n",
    "        STEP_SIZE = 400\n",
    "\n",
    "        delta = np.diff(gcps, axis=0)\n",
    "        directions = delta / np.linalg.norm(delta, axis=1).reshape(-1, 1)\n",
    "        angles = -np.arctan2(directions.T[1], directions.T[0]) * 180 / np.pi\n",
    "        delta_angles = np.append(np.diff(angles), 0)\n",
    "\n",
    "        path = []\n",
    "\n",
    "        for t1, t2, angle, delta_angle in zip(gcps, gcps[1:], angles, delta_angles):\n",
    "            steps = np.linalg.norm(t2 - t1) / STEP_SIZE\n",
    "            line = np.linspace(t1, t2, steps.astype(\"uint32\"), dtype=\"uint32\")\n",
    "            path.extend([np.array([x, y, angle]) for x, y in line])\n",
    "\n",
    "            if delta_angle == 0:\n",
    "                continue\n",
    "\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "\n",
    "            interpolated_angles = np.linspace(angle, angle + delta_angle, 3)\n",
    "            path.extend(\n",
    "                [\n",
    "                    np.array([line[-1][0], line[-1][1], theta])\n",
    "                    for theta in interpolated_angles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return path\n",
    "\n",
    "    def _next_image(self):\n",
    "        if self.mock_wait_time > 0:\n",
    "            time.sleep(self.mock_wait_time)\n",
    "\n",
    "        sample_diag = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "\n",
    "        for x, y, theta in self._path_pixels:\n",
    "            sample = self._crop_around(\n",
    "                self._mock_img_full, (y, x), (sample_diag, sample_diag)\n",
    "            )\n",
    "            \n",
    "            rotated_img = self._center_crop(\n",
    "                rotate(sample, -theta, reshape=False), self._output_dim\n",
    "            )\n",
    "            \n",
    "            theta_radians = theta / 180 * math.pi\n",
    "\n",
    "            center = np.array((x, y))\n",
    "\n",
    "            corner_gps_coords = self._get_corner_gps_coords_of_sample_img(\n",
    "                center, theta_radians\n",
    "            )\n",
    "            yield rotated_img, corner_gps_coords\n",
    "\n",
    "    def _crop_around(self, img, center, dim):\n",
    "        dim = np.array(dim).astype(\"uint32\")\n",
    "        x = int(center[1] - dim[1] // 2)\n",
    "        y = int(center[0] - dim[0] // 2)\n",
    "        return img[y : y + dim[0], x : x + dim[1]]\n",
    "\n",
    "    def _center_crop(self, img, dim):\n",
    "        return img[\n",
    "            img.shape[0] // 2 - dim[0] // 2 : img.shape[0] // 2 + dim[0] // 2,\n",
    "            img.shape[1] // 2 - dim[1] // 2 : img.shape[1] // 2 + dim[1] // 2,\n",
    "        ]\n",
    "\n",
    "    def _rotate_vec2d(self, vec2d, radians):\n",
    "        \"\"\"Only rotate a point around the origin (0, 0).\"\"\"\n",
    "        x, y = vec2d\n",
    "        x_new = x * math.cos(radians) - y * math.sin(radians)\n",
    "        y_new = x * math.sin(radians) + y * math.cos(radians)\n",
    "\n",
    "        return np.array([x_new, y_new])\n",
    "\n",
    "    def _rotate_pixel_about_center(self, xy, center, radians):\n",
    "        vector_from_center = np.array(xy) - np.array(center)\n",
    "        return self._rotate_vec2d(vector_from_center, -radians)\n",
    "\n",
    "    def _sample_pixel_to_dataset_pixel_coords(self, xy, sample_center, radians):\n",
    "        # Sample pixel coordinate system has (0,0) at the top left of the sample image\n",
    "        sample_center_in_sample_pixel_coords = (\n",
    "            np.array((self._output_dim[1], self._output_dim[0])) / 2\n",
    "        )\n",
    "        rotated_coords = self._rotate_pixel_about_center(\n",
    "            xy, sample_center_in_sample_pixel_coords, radians\n",
    "        )\n",
    "        return rotated_coords + sample_center\n",
    "\n",
    "    def _sample_pixel_to_gps_coords(self, xy, sample_center, radians):\n",
    "        \"\"\"\n",
    "        sample_center is the center coordinates (np array) of the sample image in the dataset pixel coordinate system\n",
    "        \"\"\"\n",
    "        dataset_pixel_coords = self._sample_pixel_to_dataset_pixel_coords(\n",
    "            xy, sample_center, radians\n",
    "        )\n",
    "        return self._pixel_to_gps_transform(dataset_pixel_coords)\n",
    "\n",
    "    def _get_corner_gps_coords_of_sample_img(self, center, radians):\n",
    "        \"\"\"\n",
    "        center is the center coordinates (np array) of the sample image in the dataset pixel coordinate system\n",
    "        radians is the angle that the sample image coordinate system is rotated relative to the dataset\n",
    "            coordinate system (CCW)\n",
    "        sample_dim is (height, width)\n",
    "        \"\"\"\n",
    "\n",
    "        height, width = self._output_dim\n",
    "\n",
    "        top_left_pixel = np.array((0, 0))\n",
    "        top_right_pixel = np.array((width, 0))\n",
    "        bot_left_pixel = np.array((0, height))\n",
    "        bot_right_pixel = np.array((width, height))\n",
    "\n",
    "        return [\n",
    "            self._sample_pixel_to_gps_coords(corner_pixel, center, radians)\n",
    "            for corner_pixel in [\n",
    "                top_left_pixel,\n",
    "                top_right_pixel,\n",
    "                bot_left_pixel,\n",
    "                bot_right_pixel,\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def _dataset_pixel_to_gps_transform(self, corner_gps_coords):\n",
    "        height, width = self._mock_img_full.shape[:2]\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = corner_gps_coords\n",
    "        right_vec = (top_right_gps - top_left_gps) / width\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / height\n",
    "\n",
    "        transformation = np.array(\n",
    "            [[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]]\n",
    "        )\n",
    "\n",
    "        def transform(pixel):\n",
    "            return transformation @ pixel + top_left_gps\n",
    "\n",
    "        return transform\n",
    "\n",
    "    def run(self, img=None):\n",
    "        if not self.mock:\n",
    "            assert img is not None, \"Image cannot be None\"\n",
    "            return img\n",
    "\n",
    "        return self._next_image()\n",
    "\n",
    "\n",
    "class ObjectDetectionLayer:\n",
    "    def __init__(\n",
    "        self, weights_file=None, classes_file=None, config_file=None, min_confidence=0.3\n",
    "    ):\n",
    "        self.weights_file = weights_file\n",
    "        self.config_file = config_file\n",
    "        self.classes_file = classes_file\n",
    "\n",
    "        self.net = self._load_model()\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "        self.classes = [\"car\", \"truck\", \"bus\", \"minibus\", \"cyclist\"]\n",
    "\n",
    "    def _load_model(self):\n",
    "        return cv2.dnn.readNet(self.weights_file, self.config_file)\n",
    "\n",
    "    def _get_output_layers(self, net):\n",
    "        layer_names = net.getLayerNames()\n",
    "        try:\n",
    "            output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        except:\n",
    "            output_layers = [\n",
    "                layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()\n",
    "            ]\n",
    "\n",
    "        return output_layers\n",
    "\n",
    "    def _get_bboxes_pixels(self, img):\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        Height, Width = image.shape[:2]\n",
    "        scale = 0.00392\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image, scale, (416, 416), (0, 0, 0), True, crop=False\n",
    "        )\n",
    "\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        outs = self.net.forward(self._get_output_layers(self.net))\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.5\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > self.min_confidence:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        bboxes_with_confidence = []\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "            except Exception:\n",
    "                box = boxes[i[0]]\n",
    "\n",
    "            x, y, w, h = [max(v, 0) for v in box[:4]]  # model outputs can be negative\n",
    "\n",
    "            bboxes_with_confidence.append(\n",
    "                np.array((x, x + w, y, y + h, 100 * confidences[i]))\n",
    "            )\n",
    "\n",
    "        # follows the format of x0, x1, y0, y1, confidence\n",
    "        return np.array(bboxes_with_confidence).astype(int)\n",
    "\n",
    "    def _bbox_pixels_to_gps(self, bboxes, gps_corners, img_dim):\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = gps_corners\n",
    "        right_vec = (top_right_gps - top_left_gps) / img_dim[1]\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / img_dim[0]\n",
    "\n",
    "        transformation = np.array(\n",
    "            [[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]]\n",
    "        )\n",
    "\n",
    "        def transform(bbox):\n",
    "            return transformation @ bbox + top_left_gps\n",
    "\n",
    "        return np.array([(*transform(bbox[:2]), *bbox[2:4]) for bbox in bboxes])\n",
    "\n",
    "    # Be careful using this radius. Pixel distance does not convert to latitude and longitude in the same way\n",
    "    def _convert_bbox_to_radial_representation(self, bboxes):\n",
    "        \"\"\"\n",
    "        Given a bbox in the format of x0, x1, y0, y1, confidence.\n",
    "        Returns a bbox in the format of x, y, r, confidence\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Scale by some factor (function of altitude) to convert pixels to meters\n",
    "        dx = bboxes[:, 1] - bboxes[:, 0]\n",
    "        dy = bboxes[:, 3] - bboxes[:, 2]\n",
    "        radii = np.sqrt(dx**2 + dy**2) / 2\n",
    "\n",
    "        return np.array(\n",
    "            [\n",
    "                (bboxes[:, 0] + bboxes[:, 1]) / 2,\n",
    "                (bboxes[:, 2] + bboxes[:, 3]) / 2,\n",
    "                radii,\n",
    "                bboxes[:, 4],\n",
    "            ]\n",
    "        ).T\n",
    "\n",
    "    def run(self, img, gps_sample_corners):\n",
    "        bboxes_pixels = self._get_bboxes_pixels(img)\n",
    "\n",
    "        if len(bboxes_pixels) == 0:\n",
    "            return [], []\n",
    "\n",
    "        bboxes_radial_pixels = self._convert_bbox_to_radial_representation(\n",
    "            bboxes_pixels\n",
    "        )\n",
    "        bboxes_radial_gps = self._bbox_pixels_to_gps(\n",
    "            bboxes_radial_pixels, gps_sample_corners, img.shape\n",
    "        )\n",
    "\n",
    "        return bboxes_radial_gps, bboxes_pixels  # remove the pixels bboxes later\n",
    "\n",
    "\n",
    "class MavlinkInterfaceLayer:\n",
    "    def __init__(self, protos_path=\"protos\"):\n",
    "        self.protos_path = protos_path\n",
    "        self.channel = grpc.insecure_channel(\"localhost:50051\")\n",
    "        self.stub = messaging_pb2_grpc.MessagingServiceStub(self.channel)\n",
    "\n",
    "    def run(self, bboxes):\n",
    "        if len(bboxes) == 0:\n",
    "            return\n",
    "\n",
    "        responses = []\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            encoded_bbox = str(bbox)[1:-1] # remove the brackets\n",
    "            response = self.stub.SendData(messaging_pb2.DataRequest(data=encoded_bbox))\n",
    "            responses.append(response)\n",
    "\n",
    "        return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_center = 29.643946\n",
    "# lon_center = -82.355659\n",
    "\n",
    "# lat_mile = 0.0144927536231884\n",
    "# lon_mile = 0.0181818181818182\n",
    "# lat_min = lat_center - (15 * lat_mile)\n",
    "# lat_max = lat_center + (15 * lat_mile)\n",
    "# lon_min = lon_center - (15 * lon_mile)\n",
    "# lon_max = lon_center + (15 * lon_mile)\n",
    "\n",
    "# DATASET_TOP_LEFT_GPS = np.array((lat_min, lon_min))\n",
    "# DATASET_TOP_RIGHT_GPS = np.array((lat_max, lon_min))\n",
    "# DATASET_BOT_LEFT_GPS = np.array((lat_min, lon_max))\n",
    "# DATASET_BOT_RIGHT_GPS = np.array((lat_max, lon_max))\n",
    "\n",
    "# DATASET_CORNER_GPS_COORDS = np.array(\n",
    "#     [\n",
    "#         DATASET_TOP_LEFT_GPS,\n",
    "#         DATASET_TOP_RIGHT_GPS,\n",
    "#         DATASET_BOT_LEFT_GPS,\n",
    "#         DATASET_BOT_RIGHT_GPS,\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "DATASET_TOP_LEFT_GPS = np.array((12.86308254761559, 77.5151947517078))\n",
    "DATASET_TOP_RIGHT_GPS = np.array((12.863010715187013, 77.52267023737696))\n",
    "DATASET_BOT_LEFT_GPS = np.array((12.859008245256549, 77.5151541499705))\n",
    "DATASET_BOT_RIGHT_GPS = np.array((12.858936436333265, 77.52262951527761))\n",
    "DATASET_CORNER_GPS_COORDS = np.array([DATASET_TOP_LEFT_GPS, DATASET_TOP_RIGHT_GPS, DATASET_BOT_LEFT_GPS, DATASET_BOT_RIGHT_GPS])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure to run `realtime_ui/network.py` on the side first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAADdCAYAAABOtY7oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg60lEQVR4nO3dfZBU1bnv8e/DKKi8DwpnMhAxihJMIopB0BtD4jlGiQpGFEyMXCUhb9doUucYuFZuKmVFI8ZoyDlRqUSDSRTQoHI1aJSrMVoKgkcjKkRUhBFkjCIalVef+8deu6cZprv3zPTu3j38PlW7Zs/qtbuf5qWfXm97mbsjIiLSlm7VDkBERLJLSUJERApSkhARkYKUJEREpCAlCRERKUhJQkRECqp4kjCzU8xstZmtMbMZlX59ERFJziq5TsLM6oC/A/8GNAFPAue6+/MVC0JERBKrdEtiNLDG3V929+3APGBChWMQEZGEKp0kGoH1eb83hTIREcmgfSr8etZG2R79XWY2HZgefh2VakQiIl3TP9z9oM4+SaWTRBMwJO/3wcCG1pXcfQ4wB8DMdHMpEZH2e7UcT1Lp7qYngWFmdoiZdQemAIsqHIOIiCRU0ZaEu+80s/8F3A/UATe5+3OVjEFERJKr6BTYjlB3k4hIh6xw92M7+yRacS0iIgUpSYiISEFKEiIiUpCShIiIFKQkISIiBSlJiIhIQUoSIiJSkJKEiIgUpCQhIiIFKUmIiEhBShIiIlKQkoSIiBSkJCEiIgUpSYiISEFKEiIiUlDJJGFmN5lZs5mtzCurN7MHzOzF8LN/3mMzzWyNma02sy/klY8ys2fDY7PNrK39rkVEJEOStCR+C5zSqmwGsMTdhwFLwu+Y2QiiLUmPDNf8yszqwjXXA9OBYeFo/ZwiIpIxJZOEuz8CvNWqeAIwN5zPBSbmlc9z923u/gqwBhhtZg1AH3d/3KOt8G7Ju0ZERDKqo2MSg9x9I0D4OTCUNwLr8+o1hbLGcN66vE1mNt3MlpvZ8g7GJyIiZbBPmZ+vrXEGL1LeJnefA8wB7XEtIlJNHW1JbApdSISfzaG8CRiSV28wsCGUD26jXEREMqyjSWIRMDWcTwXuziufYmY9zOwQogHqZaFL6l0zGxNmNZ2fd42IiGRUye4mM7sNGAccaGZNwI+AnwILzGwasA44G8DdnzOzBcDzwE7gO+6+KzzVt4hmSu0PLA6HiIhkmEWTjbJLYxIiIh2ywt2P7eyTaMW1iIgUpCQhIiIFKUmIiEhBShIiIlJQuRfTiUg7jRgxgvr6egAeffTRKkcjsjvNbhKpsoULF3L66acDsO+++1Y5GulCyjK7SS0JkSrbtWsXO3bsqHYYIm1SS0Kkyg4++GB69+4NwMqVK0vUFklMLQmRruDVV1+tdggiBWl2k4iIFKQkIdJFzJ49m9mzZ9OzZ89qhyJdiMYkRFI2cODA3Hlzc3ORmp0T/18+8MADefPNN1N7HakZGpMQqQXLly/PTW1taGhI7XXiNRaaKSXlpJaESMq2b9+eSxLRdirp2Gef6Dvfzp07U3sNqSmVaUmY2RDgFuBfgA+BOe7+CzOrB+YDQ4G1wDnuvjlcMxOYBuwCvuvu94fyUbTsKfEn4GLPepYS6aQLL7yQbt3SH/5TcpBUuHvRA2gAjgnnvYG/AyOAWcCMUD4DuCqcjwCeAXoAhwAvAXXhsWXAWKI9rxcDpyZ4fdehQ0fljt69e3vv3r2rHoeOTh/LS32+JjlKfr1x943u/lQ4fxd4AWgEJgBzQ7W5wMRwPgGY5+7b3P0VYA0wOuyF3cfdHw+th1vyrhGRjFixYgUrVqyodhiSEe0auDazocDRwFJgUNi7GnffaGbxFI5G4Im8y5pC2Y5w3rpcRDJk2LBh1Q5BMiRxkjCzXsAfgUvc/Z0iA3BtPeBFytt6renA9KSxiVRTPGAMXWNc4D/+4z+qHYJkSKIkYWb7EiWIP7j7wlC8ycwaQiuiAYgngDcBQ/IuHwxsCOWD2yjfg7vPAeaE124zkYhkxYMPPpg7HzduXPUCKZOf/exn1Q5BsiTBwLERjR9c16r8anYfuJ4Vzo9k94Hrl2kZuH4SGEPLwPV4DVzrqPUjX7Vj0aEj7yjLwHWSlsQJwFeBZ83s6VD2v4GfAgvMbBqwDjgbwN2fM7MFwPPATuA77r4rXPctWqbALg6HSE274YYbqh2CSGq0mE5EpGsqy2I63eBPREQKUpIQEZGClCRERKQg3QVWpITLL788d/7DH/6wipGIVJ4GrkVKyP8/kuZdXEXKTPtJiFTC008/Xe0QRKpGLQnJlFNOOYUzzjgDgG9/+9tVjiay33775c63bt1axUj2NG/ePABuvPFGHnrooSpHIxlTlpZEp1fjpX1Q/VWLOip4zJw5U6uX23HEvva1r1U9Fh2ZOyq24lqkU0aOHAkk67ZZv349jzzySLoBdSGLFi0C4NVXX61yJNJVqbtJUvfBBx8AsP/++5es261bt9wubqXuqDpx4sTc+V133dXh+GpZPJCe9f/HUhVl6W5SkpB2y5/hk+Tfz/bt2wHo3r17WeP48MMPc+ed2R70tNNOy53fc889nYqpXEaOHEldXR2ANgCSjlKSkOqYPn167oM1HmQuZsyYMQA88cQTJWq2z1tvvZU7r6+v7/DzlCvZlNPGjRvp378/sPvAeUeNHj0agGXLlnX6uaRmaAqsVMcnP/lJTj/99MT1y50cYvFYRxKNjdEmiK+99toej23ZsqVcIZWNmZV1TcZf//pXAHr06FG255S9g5KEAHDSSScBsGTJkpJ1V6xYkZt6WU3r1q1LXDceND/ooIP2eOzoo48uV0hlM378+N12vOusrPcYSHapu0mAlkHicn4wZUncpZSF7qRqDDYfe2zU67B8+fKKvaZUXWW6m8xsP+ARop3m9gHucPcfmVk9MB8YCqwFznH3zeGamcA0YBfwXXe/P5SPomXToT8BF3vWs1SN6tatW27gc8eOHSXrxzOQuqopU6YkrhsnkvyxinKKW2GTJ09O5fnbouQgHZZgMZsBvcL5vsBSoi1IZ7H79qVXhfMR7L596Uu0bF+6DBhLy/alp2oxXTrHueee64899pg/9thjieoPHz7chw8fXvW4s3Dce++9fu+996b2/FldLGhmuaPasegoy1GZxXThH/M/w6/7hsOBCcC4UD4XeBj4QSif5+7bgFfMbA0w2szWAn3c/XEAM7sFmIi2ME1FY2Mjxx9/fOL6q1atSjGa6hoyZEjufP369SXrjx8/Ps1wuPvuu1N9/o66/fbbc+eTJk2qYiSSJYk6oM2sDlgBHAb8l7svNbNB7r4RwN03mtnAUL0RyJ/O0hTKdoTz1uWS0DnnnAPAggULStZdsWIFs2fPTjukmpC/0nvAgAEl6//+979PMRo488wzU33+jjrrrLOqHYJkUKIk4e67gJFm1g+408w+UaR6W/P2vEj5nk9gNh2YniS2vUncl50kSTz00EO64VsQrzdI6qtf/Wqien379uWCCy4A4LrrrstNyX355Zd55513Cl6X1WG4P/7xj9UOQTKoXVNZ3P1tM3sYOAXYZGYNoRXRADSHak3AkLzLBgMbQvngNsrbep05wBzo2rOb6urqcvPW33///ZL133zzzbRD6pLOPvvsVJ53wIABXHvttUCUJB5//HEgaincd999qbxmmtL6c5LalmR200HAjpAg9gf+FbgKWARMBX4afsYdrYuAW83s58BHgGHAMnffZWbvmtkYosHv84FflvsN1ZKTTz6Za665BoARI0aUrH/UUUelHVKXlNY35J07d/LSSy/lfo9nk9XqxkRZbeFIdSVpSTQAc8O4RDdggbvfY2aPAwvMbBqwDjgbwN2fM7MFwPPATuA7obsK4Fu0TIFdzF4+aN23b18+/vGPJ66/YUObDS+pkqamJo455pjc7+PGjQPghRde2KPuJz7R0kO7cuXK1GNLk9Zc7F20mK7MLrroIgB++cvSjaQRI0bkBjF/8pOfpBqXVNd7772XO+/Zs2cVI+m8bdu2AbrFRw3QDf6yKP7zrNUuh1qUf3fZ+I6z5XTttddy4IEHAskHtVvLX9C47777liWualGSqBm6wV8WrV27NlG9hoYGILrbp3TOo48+mjuP73ZaTmeeeSYHH3ww0PEkEd8bK4n4rq/btm3L5DjBCSecUO0QpILUkiizfv36AfD2228XrdfcHE0GGzhwYNF6Ulr+v+E0WnA33XRT7saA7bn7bUfF6zrOOOOMdt3EUKQVtSSyqFRyiLV1N1LpmKuvvjrV5582bVpFuw/jWWzl3qSp0rRrXtegJFElX/7ylxPVmzNnDhBt9CNtu/TSSzt8bTzrqNiMo7z7iFXE5ZdfDuy+qVItihd9av1FbVN3U8ZpIDxd8ayjWp1xdN111wFwySWXVDWOtujfbtVpdtPeIN4EqNjA5+GHH07v3r0B7YfcXvGso1qdcZTlD+J4EaPuCVU1ShJ7g3gV765duwrWWbx4MZ/73OeA8uyHvDc58cQTAXjkkUeqHEnHPPbYY0A2ZxxpTKLqNHC9NyiWHPIl+SaZv+tcvBNdLfjFL34BwOuvv86VV15Z1ueu1eQQi1d5J3HyyScD8Oc//zmlaHan5NA1qCXRBRxxxBH07dsXgGXLlhWs9/DDD+fO2/PhUm3xv9FVq1Ylvo3JzTffDMCPf/zjxGtXurr4C0fcOs2CMWPG5M6feOKJIjWlA9TdJO2T9nqCtMRdKmvXruUrX/lKomvi9/rpT39a9xgK4tuX9+nTp8qRtMhfIV/rU34zSN1N0j433HBDonrx5kZLlizJxO3J41ZPe77QxF0qxfZ12NvEN+YrJX8NzxtvvJFWOEDy7lSpHrUkZA8ffvghAMcff3zNdgF069YNaHkvktxrr72WO29sTHfzyHijJth9B0EpC7UkJB1x66HU4HY8DrJly5bUY4odfvjhuQRQbF9uJYeO+8hHPlKx11JiyD4lCdlD/O2uVFfDU089BcChhx6adkg5Dz74YG470nhtiJTXhRdemLhupaa5ajpt9STubgqbDi0HXnP308ysHpgPDAXWAue4++ZQdyYwDdgFfNfd7w/lo2jZdOhPwMVeIgB1N2VXuRZyTZkyBYA1a9aUHGRubm6mvr4e2H1Kr1RHfOuNFStWcNVVV6X2OnfddRcAEydOTO01uqCKdzddDLwAxFMjZgBL3P2nZjYj/P4DMxsBTAGOJNq+9EEzOzzsTnc9MB14gihJnMJevjtdLfve976XqN4Pf/hDoOWeRK3ddtttAFx//fUlk8SkSZNqdnV0VxTflyntRZwTJkxI9fmliPjmZcUOYDCwBPg8cE8oWw00hPMGYHU4nwnMzLv2fmBsqLMqr/xc4MYEr+06avuIFXq8ubnZm5ubfdasWVWPVUf7joULF/rChQt95syZqb7O/Pnzff78+VV/vzV2LE/y+V7qSNqSuA64FMjvBB7k7hsB3H2jmcUbIzQStRRiTaFsRzhvXb4HM5tO1OKQLqDUns5HHXUU3bt3Z9asWcyZM0d3vK0h7bkv09e//nUguqdTe+9wO3ny5HbVlzJK8E3+NOBX4XwcLS2Jt1vV2xx+/hdwXl75b4CzgE8DD+aVfwb4v2pJdP3jgAMO8AMOOKBoneHDh5dsceio7SP2qU99quqx7CVHxVoSJwBnmNl4YD+gj5n9HthkZg2hFdEANIf6TcCQvOsHAxtC+eA2yqWLe//990vW6datW6Jpq/mD5JrpUluamqKOhDT2IY/Ft/mo1fU9WdSuxXRmNg749zC76WrgzbyB63p3v9TMjgRuBUYTDVwvAYa5+y4zexK4CFhKNHD9S3f/U4nX1CfBXqBXr1585jOfAaK72hZy++235861mU1tGTBgABDt3lhqpfVhhx0GRDPe2iNOQLrFB1Cm2U3tanawe3fTAKIE8GL4WZ9X7zLgJaLB7VPzyo8FVobH/pOQpNTd1LWPww47zA877DDv2bNnp58rX7Xfl470ji1btviWLVvafd3WrVt969atVY8/I0dZupt0Ww5JXXz/pMmTJxdtJSQRb2QDxQdN4/013n33Xd3grwZ19I61xxxzDNCy0HMvp9tySG2ItwYtx+K3SZMmJar3wAMPANEir+OOO67TryuVddpppyWuG6+b2bFjh5JDCpQkJHXjx48HyvPtLmnL94MPPgBKD5L26NEDgG3btnUuMCmr9rQ4442jxo4dm6i+Jj+0j7qbpEsaPnw4AFu3bi266VC8J/ioUaMqEZakIP4MS3p7mDvvvDN3fuaZZ6YSU0Zo0yGRzmrvB4xkz89//nMAvv/97yeqn/+Z18X/3jUmIdJZV1xxRaJ63/zmN4HkGzdJ5SRNDgA/+tGPgJYbE0ppakmIJKAWR9cQ/z3Ge5Jk/fOvk9SSEKmU9evXJ6o3aNAgADZt2pRmONJBzz77LNDlk0NZqSUhkkC8h0WpG9Nt3LgRgIaGhtRjkvbbf//9gZbZb8XEU6eXLl2aakwp0sC1SNaoW6rriKdFx9Oka5C6m0SyZurUqSXrXHHFFblvtEk3bpLKy/oX6EpRS0KkwjZv3ky/fv0AtTiyLF47E6+lqUFqSYjUoieffJJevXqVrDdy5Mjc+dNPP51eQNKmGk4OZaWWhEiF5e/RvWPHjoL18gdX4+4pkXZQS0KkFhVLDPmS3gE1nvOfZNMmkfZKlCTMbC3wLrAL2Onux5pZPTAfGAqsBc5x982h/kxgWqj/XXe/P5SPAn4L7E+06dDFnvWmjEiVjBs3LlG9e+65B4AvfelLbN26NcWIZK+UcLOhtcCBrcpmATPC+QzgqnA+AngG6AEcQrTBUF14bBkwFjBgMXkbEmnTIR06OnbEyrGpk44udVRsj+tCJhDtVAcwF3gY+EEon+fu24BXzGwNMDq0Rvq4++MAZnYLMJEoWYhIB/3ud78DYOfOnUXrxXc8zb8LqkgpSZOEA38Og8g3uvscYJC7bwRw941mNjDUbQTydyFvCmU7wnnrchHphPPPPz9RvXhXv3gMQySJpEniBHffEBLBA2a2qkjdtiZ+e5HyPZ/AbDowPWFsIpLA5s2bE9Xr3bs3EG39KpIoSbj7hvCz2czuBEYDm8ysIbQiGoDmUL0JGJJ3+WBgQygf3EZ5W683B5gDmgIrUi5HH310onrx+oDDDz88zXCkRpRsd5pZTzPrHZ8DJwMrgUXA1FBtKnB3OF8ETDGzHmZ2CDAMWBa6pt41szEWLTM9P+8aEUnZunXrWLduXcl6w4YNY9iwYRWISGpBkpbEIODOcPuAfYBb3f0+M3sSWGBm04B1wNkA7v6cmS0Angd2At9x913hub5FyxTYxWjQWiRzLr300pJ1hgwZwnnnnQfAlVdemXZIUkVacS0i7XbiiSfyl7/8BdD9pzJMK65FpDref/99Vq0qNn8lMnTo0Nz52rVr0wtIUqOWhIi0W7du3XL3k3rvvfcK1sufUdW/f//U45LdqCUhItXx4YcfFk0Osb59+1YgGkmTkoSIpGbChAmJ6s2dOxeAv/3tb1xzzTVphiTtpO4mEam6+HPovvvu49RTT61yNF2GuptEpGu47777AFi+fHnReieeeCIAjzzySOoxSUQtCRGpuvh+Unl3f25TvBdH/sZNUpBaEiJZ8dGPfhQg0Ypm2VPSDZOSbtgUJ5Gk9aUwJQmRMoj3oK6vry9ab/To0UybNg2Ab3zjG0XrHnnkkbnz5557rmjd/AVtWe8d6IzRo0cnqvfwww8DcMIJJ6QYzd5B3U0iZRB/Ey51G+5zzz2XW2+9FSi9Ujl/imnPnj2L1r3jjjty55MmTSpa9/jjjwdg+/btJccAanVr1PhzbS9fDa7uJpGsOOussxLVa25u5qGHHkpUt3v37mV/fWj5lr1hw4bdVkS3ZfHi6PZq55xzDlu2bCla94tf/CIA9957b8kY4ve2ffv2knU7Yvbs2YnqXXDBBQDcfPPNqcTRFaglIVJBZpb7dr5r166idT/72c/mzuP7JBXSnpbEBx98AERJ4tBDDy1aN/58GDhwIG+88UbRuvH7qaurK1oPYOnSpQAcd9xxJetOmTIFgHnz5pWs26tXLwD++c9/lqwLXb7FUZaWhJKESBfQnjGJo446CogGdZ9//vmidW+66SYALr744pKbEL399tsA9OvXr0S07ftwbk/d1atXA3DEEUcUrTdw4EAmT57M7Nmz2bBhA42NhTfJ7N+/f+6133rrrZIxZIiShIhkR9x1leRGfrNmzQKS3Za8uTnaz2zgwIElaiZPKKNGjcqNxxx00EH84x//KFj3xRdfzHWPHXzwwSVjyBCNSYhIdrTnLq9JkkMsbvkkMWPGjET1tm3blou3WIKAaO+MHj16JI6hq0nUkjCzfsCvgU8Q7Ut9IbAamA8MBdYC57j75lB/JjAN2AV8193vD+WjaNl06E/AxV4iALUkRKTc6urqcnt5x91khUyfPj03znL99denHVo5laUlkVvhWOwA5gJfC+fdgX7ALGBGKJsBXBXORwDPAD2AQ4CXgLrw2DJgLGBEu9KdmuC1XYcOHTp0tPtYnuTzvdSRZI/rPsCJwG8A3H27u78NTCBKHoSfE8P5BGCeu29z91eANcBoM2sA+rj746H1cEveNSIikkElkwTwMeAN4GYz+28z+7WZ9QQGuftGgPAzHlVqBNbnXd8UyhrDeevyPZjZdDNbbmbFV/qIiEiqkiSJfYBjgOvd/WjgPaLupULamlbgRcr3LHSf4+7HlqU/TUREOixJkmgCmtx9afj9DqKksSl0IRF+NufVH5J3/WBgQygf3Ea5iIhkVMkk4e6vA+vNLF6dchLwPLAImBrKpgJ3h/NFwBQz62FmhwDDgGWhS+pdMxtj0STm8/OuERGRDEq6TuIi4A9m1h14GbiAKMEsMLNpwDrgbAB3f87MFhAlkp3Ad9w9vv/At2iZArs4HCIiklFacS0i0jWVZZ1EkjEJERHZSylJiIhIQUoSIiJSkJKEiIgUpCQhIiIFKUmIiEhBShIiIlKQkoSIiBSkJCEiIgUpSYiISEFKEiIiUpCShIiIFKQkISIiBSlJiIhIQSWThJkdYWZP5x3vmNklZlZvZg+Y2YvhZ/+8a2aa2RozW21mX8grH2Vmz4bHZofNh0REJKOS7Ey32t1HuvtIYBTwPnAn0T7XS9x9GLAk/I6ZjQCmAEcCpwC/MrO68HTXA9OJdqsbFh4XEZGMam9300nAS+7+KjABmBvK5wITw/kEYJ67b3P3V4A1wOiwD3Yfd3/co52Obsm7RkREMqi9SWIKcFs4HxT2rSb8HBjKG4H1edc0hbLGcN66XEREMipxkgj7W58B3F6qahtlXqS8rdeabmbLzWx50vhERKT82tOSOBV4yt03hd83hS4kws/mUN4EDMm7bjCwIZQPbqN8D+4+x92PLcf+rCIi0nHtSRLn0tLVBLAImBrOpwJ355VPMbMeZnYI0QD1stAl9a6ZjQmzms7Pu0ZERDLIojHkEpXMDiAaZ/iYu28JZQOABcBHgXXA2e7+VnjsMuBCYCdwibsvDuXHAr8F9gcWAxd5iQDMrHSAIiLS2opy9MYkShLVpCQhItIhZUkSWnEtIiIFKUmIiEhBShIiIlKQkoSIiBSkJCEiIgUpSYiISEFKEiIiUpCShIiIFKQkISIiBSlJiIhIQUoSIiJSkJKEiIgUpCQhIiIFKUmIiEhBShIiIlKQkoSIiBS0T7UDSOCfwOpqB9FBBwL/qHYQHaTYq6eW41fs1dFW7AeX44lrIUmsLsfuStVgZssVe+XVcuxQ2/Er9upIM3Z1N4mISEFKEiIiUlAtJIk51Q6gExR7ddRy7FDb8Sv26kgtdnP3tJ5bRERqXC20JEREpEoymyTM7BQzW21ma8xsRrXjATCzIWb2kJm9YGbPmdnFobzezB4wsxfDz/5518wM72G1mX0hr3yUmT0bHpttZlah91BnZv9tZvfUUuxm1s/M7jCzVeHPf2wNxf698O9lpZndZmb7ZTl2M7vJzJrNbGVeWdniNbMeZjY/lC81s6Epx351+HfzNzO708z61UrseY/9u5m5mR1Y8djdPXMHUAe8BHwM6A48A4zIQFwNwDHhvDfwd2AEMAuYEcpnAFeF8xEh9h7AIeE91YXHlgFjAQMWA6dW6D18H7gVuCf8XhOxA3OBr4Xz7kC/WogdaAReAfYPvy8A/meWYwdOBI4BVuaVlS1e4NvADeF8CjA/5dhPBvYJ51fVUuyhfAhwP/AqcGClY0/1P3Yn/rDGAvfn/T4TmFntuNqI827g34gW+zWEsgaitR17xB3+oseGOqvyys8FbqxAvIOBJcDnaUkSmY8d6EP0QWutymsh9kZgPVBPtC7pnvChlenYgaHs/kFbtnjjOuF8H6JFYJZW7K0eOxP4Qy3FDtwBHAWspSVJVCz2rHY3xf+xYk2hLDNCU+1oYCkwyN03AoSfA0O1Qu+jMZy3Lk/bdcClwId5ZbUQ+8eAN4CbQ1fZr82sZy3E7u6vAT8D1gEbgS3u/udaiL2Vcsabu8bddwJbgAGpRb67C4m+Xe8WR6sYMxO7mZ0BvObuz7R6qGKxZzVJtNXXmplpWGbWC/gjcIm7v1OsahtlXqQ8NWZ2GtDs7iuSXtJGWVViJ/rWcwxwvbsfDbxH1OVRSGZiD333E4i6BD4C9DSz84pd0kZZtf7ck+hIvFV5L2Z2GbAT+EOJODIRu5kdAFwG/J+2Hi4QR9ljz2qSaCLqh4sNBjZUKZbdmNm+RAniD+6+MBRvMrOG8HgD0BzKC72PpnDeujxNJwBnmNlaYB7weTP7PbURexPQ5O5Lw+93ECWNWoj9X4FX3P0Nd98BLASOr5HY85Uz3tw1ZrYP0Bd4K7XIo9eZCpwGfMVDfwvZj/1Qoi8Xz4T/t4OBp8zsXyoZe1aTxJPAMDM7xMy6Ew2yLKpyTIRZAr8BXnD3n+c9tAiYGs6nEo1VxOVTwqyCQ4BhwLLQXH/XzMaE5zw/75pUuPtMdx/s7kOJ/jz/n7ufVyOxvw6sN7MjQtFJwPO1EDtRN9MYMzsgvOZJwAs1Enu+csab/1yTiP4tptaSMLNTgB8AZ7j7+63eU2Zjd/dn3X2guw8N/2+biCbOvF7R2Ms14FLuAxhPNHvoJeCyascTYvofRM2zvwFPh2M8Ub/eEuDF8LM+75rLwntYTd5sFOBYYGV47D8p4+BXgvcxjpaB65qIHRgJLA9/9ncB/Wso9h8Dq8Lr/o5oRkpmYwduIxo/2UH0wTStnPEC+wG3A2uIZuJ8LOXY1xD1xcf/Z2+oldhbPb6WMHBdydi14lpERArKaneTiIhkgJKEiIgUpCQhIiIFKUmIiEhBShIiIlKQkoSIiBSkJCEiIgUpSYiISEH/HzYCfpCkHcFsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[973 996 968 999  51]]\n",
      "[[643 676 545 599  89]\n",
      " [776 829 695 783  75]]\n",
      "[[186 217 543 601  90]]\n",
      "[[890 959 626 689  99]]\n",
      "[[442 500 622 693  99]\n",
      " [728 801 871 942  99]\n",
      " [370 411 415 478  57]]\n",
      "[[280 349 872 941  99]\n",
      " [  0  56 630 694  98]]\n",
      "[[836 886 339 368  85]]\n",
      "[[367 419 340 364  62]]\n",
      "[[785 879   0  27  99]]\n",
      "[[300 397   0  27  98]]\n",
      "[[817 891 109 136  99]]\n",
      "[[334 407 108 135  99]]\n",
      "[[ 516  584   99  147   98]\n",
      " [ 945 1001  158  209   97]]\n",
      "[[ 516  584   99  147   98]\n",
      " [ 945 1001  158  209   97]]\n",
      "[[ 516  584  100  147   98]\n",
      " [ 944 1002  157  209   97]]\n",
      "[[ 515  583  101  147   96]\n",
      " [ 943 1001  156  210   90]]\n",
      "[[ 515  583  101  147   96]\n",
      " [ 943 1001  156  210   90]]\n",
      "[[ 37 105  98 147  97]]\n",
      "[[800 878 390 422  99]\n",
      " [549 622 410 445  99]]\n",
      "[[323 400 391 423  99]\n",
      " [712 782 379 411  99]\n",
      " [ 70 146 409 447  99]]\n",
      "[[233 307 378 408  99]]\n",
      "[[  0  10 485 521  70]]\n",
      "[[543 628 526 555  99]]\n",
      "[[ 66 152 525 556  99]]\n",
      "[[610 678 618 647  99]\n",
      " [948 997 749 767  77]]\n",
      "[[610 678 618 647  99]\n",
      " [948 997 749 767  77]]\n",
      "[[359 430 311 352  99]\n",
      " [ 84 127 120 145  96]]\n",
      "[[526 596 658 715  99]\n",
      " [767 813 934 979  71]]\n",
      "[[526 596 658 715  99]\n",
      " [767 813 934 979  71]]\n",
      "[[ 27  98 659 713  99]\n",
      " [266 315 932 977  68]]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(40)\n",
    "\n",
    "mock_image_path = \"../realtime_ui/data/Copy of Blore_Clean.tif\"\n",
    "\n",
    "img_layer = ImageProcessingLayer(\n",
    "    mock_wait_time=1,\n",
    "    mock_corner_gps_coords=DATASET_CORNER_GPS_COORDS,\n",
    "    mock_image_path=mock_image_path,\n",
    ")\n",
    "\n",
    "# For illustration, show the mock path\n",
    "pathtrace = np.zeros(img_layer._mock_img_full.shape[:2])\n",
    "for pixel in img_layer._path_pixels:\n",
    "    y, x = pixel[:2].astype(int)\n",
    "    pathtrace[x-50:x+50, y-50:y+50] = 1\n",
    "plt.imshow(pathtrace, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "weights_file = \"../raspberry_pi_code/weights/yolov3-aerial.weights\"\n",
    "classes_file = \"../raspberry_pi_code/weights/aerial.names\"\n",
    "config_file = \"../raspberry_pi_code/weights/yolov3-aerial.cfg\"\n",
    "\n",
    "obj_layer = ObjectDetectionLayer(\n",
    "    config_file=config_file, weights_file=weights_file, classes_file=classes_file\n",
    ")\n",
    "\n",
    "mav_layer = MavlinkInterfaceLayer()\n",
    "\n",
    "for img, img_corner_gps in img_layer.run():\n",
    "    bboxes_gps, bboxes_pixels = obj_layer.run(img, img_corner_gps)\n",
    "    responses = mav_layer.run(bboxes_gps)\n",
    "\n",
    "    if len(bboxes_gps) != 0 and len(responses) == 0:\n",
    "        print(\"No responses from MAVLink\")\n",
    "\n",
    "    if responses:    \n",
    "        print(bboxes_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6801c18e8f98d131d679b452329ec4c6c6e2a07180fd911726b1fa2ebd3319cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
