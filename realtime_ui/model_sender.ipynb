{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./protos\")\n",
    "\n",
    "import grpc\n",
    "import messaging_pb2\n",
    "import messaging_pb2_grpc\n",
    "\n",
    "\n",
    "class ImageProcessingLayer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim=(1000, 1000),\n",
    "        mock=True,\n",
    "        mock_image_path=None,\n",
    "        mock_num_samples=10,\n",
    "        mock_wait_time=1,\n",
    "        mock_corner_gps_coords=None,\n",
    "    ):\n",
    "        self.mock = mock\n",
    "\n",
    "        if not mock:\n",
    "            return\n",
    "\n",
    "        self.mock_wait_time = mock_wait_time\n",
    "\n",
    "        if mock_image_path is None:\n",
    "            # mock_image_path = \"data/demo.jpg\"\n",
    "            mock_image_path = \"../data/demo.jpg\"\n",
    "\n",
    "        self._mock_img_full = np.asarray(Image.open(mock_image_path))[:, :, :3]\n",
    "\n",
    "        self._output_dim = output_dim\n",
    "        diag_len = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "        self._gcps_pixels = self._generate_random_gcps(\n",
    "            self._mock_img_full, mock_num_samples, padding=(diag_len, diag_len)\n",
    "        )\n",
    "\n",
    "        self._mock_corner_gps_coords = mock_corner_gps_coords\n",
    "        self._pixel_to_gps_transform = self._dataset_pixel_to_gps_transform(\n",
    "            self._mock_corner_gps_coords\n",
    "        )\n",
    "\n",
    "        self._path_pixels = self._build_path_pixels(self._gcps_pixels)\n",
    "\n",
    "    def _generate_random_gcps(self, img, num_samples, padding=(0, 0)):\n",
    "        return np.random.randint(\n",
    "            padding,\n",
    "            high=(\n",
    "                img.shape[1] - padding[0] - 10,\n",
    "                img.shape[0] - padding[1] - 10,\n",
    "            ),\n",
    "            size=(num_samples, 2),\n",
    "        )\n",
    "\n",
    "    def _build_path_pixels(self, gcps):\n",
    "        STEP_SIZE = 400\n",
    "\n",
    "        delta = np.diff(gcps, axis=0)\n",
    "        directions = delta / np.linalg.norm(delta, axis=1).reshape(-1, 1)\n",
    "        angles = -np.arctan2(directions.T[1], directions.T[0]) * 180 / np.pi\n",
    "        delta_angles = np.append(np.diff(angles), 0)\n",
    "\n",
    "        path = []\n",
    "\n",
    "        for t1, t2, angle, delta_angle in zip(gcps, gcps[1:], angles, delta_angles):\n",
    "            steps = np.linalg.norm(t2 - t1) / STEP_SIZE\n",
    "            line = np.linspace(t1, t2, steps.astype(\"uint32\"), dtype=\"uint32\")\n",
    "            path.extend([np.array([x, y, angle]) for x, y in line])\n",
    "\n",
    "            if delta_angle == 0:\n",
    "                continue\n",
    "\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "\n",
    "            interpolated_angles = np.linspace(angle, angle + delta_angle, 3)\n",
    "            path.extend(\n",
    "                [\n",
    "                    np.array([line[-1][0], line[-1][1], theta])\n",
    "                    for theta in interpolated_angles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return path\n",
    "\n",
    "    def _next_image(self):\n",
    "        if self.mock_wait_time > 0:\n",
    "            time.sleep(self.mock_wait_time)\n",
    "\n",
    "        sample_diag = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "\n",
    "        for x, y, theta in self._path_pixels:\n",
    "            sample = self._crop_around(\n",
    "                self._mock_img_full, (y, x), (sample_diag, sample_diag)\n",
    "            )\n",
    "            \n",
    "            rotated_img = self._center_crop(\n",
    "                rotate(sample, -theta, reshape=False), self._output_dim\n",
    "            )\n",
    "            \n",
    "            theta_radians = theta / 180 * math.pi\n",
    "\n",
    "            center = np.array((x, y))\n",
    "\n",
    "            corner_gps_coords = self._get_corner_gps_coords_of_sample_img(\n",
    "                center, theta_radians\n",
    "            )\n",
    "\n",
    "            yield rotated_img, corner_gps_coords\n",
    "\n",
    "    def _crop_around(self, img, center, dim):\n",
    "        dim = np.array(dim).astype(\"uint32\")\n",
    "        x = int(center[1] - dim[1] // 2)\n",
    "        y = int(center[0] - dim[0] // 2)\n",
    "        return img[y : y + dim[0], x : x + dim[1]]\n",
    "\n",
    "    def _center_crop(self, img, dim):\n",
    "        return img[\n",
    "            img.shape[0] // 2 - dim[0] // 2 : img.shape[0] // 2 + dim[0] // 2,\n",
    "            img.shape[1] // 2 - dim[1] // 2 : img.shape[1] // 2 + dim[1] // 2,\n",
    "        ]\n",
    "\n",
    "    def _rotate_vec2d(self, vec2d, radians):\n",
    "        \"\"\"Only rotate a point around the origin (0, 0).\"\"\"\n",
    "        x, y = vec2d\n",
    "        x_new = x * math.cos(radians) - y * math.sin(radians)\n",
    "        y_new = x * math.sin(radians) + y * math.cos(radians)\n",
    "\n",
    "        return np.array([x_new, y_new])\n",
    "\n",
    "    def _rotate_pixel_about_center(self, xy, center, radians):\n",
    "        vector_from_center = np.array(xy) - np.array(center)\n",
    "        return self._rotate_vec2d(vector_from_center, -radians)\n",
    "\n",
    "    def _sample_pixel_to_dataset_pixel_coords(self, xy, sample_center, radians):\n",
    "        # Sample pixel coordinate system has (0,0) at the top left of the sample image\n",
    "        sample_center_in_sample_pixel_coords = (\n",
    "            np.array((self._output_dim[1], self._output_dim[0])) / 2\n",
    "        )\n",
    "        rotated_coords = self._rotate_pixel_about_center(\n",
    "            xy, sample_center_in_sample_pixel_coords, radians\n",
    "        )\n",
    "        coords = rotated_coords + sample_center\n",
    "        return coords\n",
    "\n",
    "    def _sample_pixel_to_gps_coords(self, xy, sample_center, radians):\n",
    "        \"\"\"\n",
    "        sample_center is the center coordinates (np array) of the sample image in the dataset pixel coordinate system\n",
    "        \"\"\"\n",
    "        dataset_pixel_coords = self._sample_pixel_to_dataset_pixel_coords(\n",
    "            xy, sample_center, radians\n",
    "        )\n",
    "        return self._pixel_to_gps_transform(dataset_pixel_coords)\n",
    "\n",
    "    def _get_corner_gps_coords_of_sample_img(self, center, radians):\n",
    "        \"\"\"\n",
    "        center is the center coordinates (np array) of the sample image in the dataset pixel coordinate system\n",
    "        radians is the angle that the sample image coordinate system is rotated relative to the dataset\n",
    "            coordinate system (CCW)\n",
    "        sample_dim is (height, width)\n",
    "        \"\"\"\n",
    "\n",
    "        height, width = self._output_dim\n",
    "\n",
    "        top_left_pixel = np.array((0, 0))\n",
    "        top_right_pixel = np.array((width, 0))\n",
    "        bot_left_pixel = np.array((0, height))\n",
    "        bot_right_pixel = np.array((width, height))\n",
    "\n",
    "        return [\n",
    "            self._sample_pixel_to_gps_coords(corner_pixel, center, radians)\n",
    "            for corner_pixel in [\n",
    "                top_left_pixel,\n",
    "                top_right_pixel,\n",
    "                bot_left_pixel,\n",
    "                bot_right_pixel,\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def _dataset_pixel_to_gps_transform(self, corner_gps_coords):\n",
    "        height, width = self._mock_img_full.shape[:2]\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = corner_gps_coords\n",
    "        right_vec = (top_right_gps - top_left_gps) / width\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / height\n",
    "\n",
    "        transformation = np.array(\n",
    "            [[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]]\n",
    "        )\n",
    "\n",
    "        def transform(pixel):\n",
    "            return transformation @ pixel + top_left_gps\n",
    "\n",
    "        return transform\n",
    "\n",
    "    def run(self, img=None):\n",
    "        if not self.mock:\n",
    "            assert img is not None, \"Image cannot be None\"\n",
    "            return img\n",
    "\n",
    "        return self._next_image()\n",
    "\n",
    "\n",
    "class ObjectDetectionLayer:\n",
    "    def __init__(\n",
    "        self, weights_file=None, classes_file=None, config_file=None, min_confidence=0.3\n",
    "    ):\n",
    "        self.weights_file = weights_file\n",
    "        self.config_file = config_file\n",
    "        self.classes_file = classes_file\n",
    "\n",
    "        self.net = self._load_model()\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "        self.classes = [\"car\", \"truck\", \"bus\", \"minibus\", \"cyclist\"]\n",
    "\n",
    "    def _load_model(self):\n",
    "        net = cv2.dnn.readNet(self.weights_file, self.config_file)\n",
    "        return net\n",
    "\n",
    "    def _get_output_layers(self, net):\n",
    "        layer_names = net.getLayerNames()\n",
    "        try:\n",
    "            output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        except:\n",
    "            output_layers = [\n",
    "                layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()\n",
    "            ]\n",
    "\n",
    "        return output_layers\n",
    "\n",
    "    def _get_bboxes_pixels(self, img):\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        Height, Width = image.shape[:2]\n",
    "        scale = 0.00392\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image, scale, (416, 416), (0, 0, 0), True, crop=False\n",
    "        )\n",
    "\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        outs = self.net.forward(self._get_output_layers(self.net))\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.5\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > self.min_confidence:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        bboxes_with_confidence = []\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "            except:\n",
    "                box = boxes[i[0]]\n",
    "\n",
    "            x, y, w, h = [max(v, 0) for v in box[:4]]  # model outputs can be negative\n",
    "            \n",
    "            bboxes_with_confidence.append(\n",
    "                np.array((x, x + w, y, y + h, 100 * confidences[i]))\n",
    "            )\n",
    "\n",
    "        # follows the format of x0, x1, y0, y1, confidence\n",
    "        return np.array(bboxes_with_confidence).astype(int)\n",
    "\n",
    "    def _bbox_pixels_to_gps(self, bboxes, gps_corners, img_dim):\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = gps_corners\n",
    "        right_vec = (top_right_gps - top_left_gps) / img_dim[1]\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / img_dim[0]\n",
    "\n",
    "        transformation = np.array(\n",
    "            [[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]]\n",
    "        )\n",
    "\n",
    "        def transform(bbox):\n",
    "            return transformation @ bbox + top_left_gps\n",
    "\n",
    "        return np.array([(*transform(bbox[:2]), *bbox[2:4]) for bbox in bboxes])\n",
    "\n",
    "    # Be careful using this radius. Pixel distance does not convert to latitude and longitude in the same way\n",
    "    def _convert_bbox_to_radial_representation(self, bboxes):\n",
    "        \"\"\"\n",
    "        Given a bbox in the format of x0, x1, y0, y1, confidence.\n",
    "        Returns a bbox in the format of x, y, r, confidence\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Scale by some factor (function of altitude) to convert pixels to meters\n",
    "        dx = bboxes[:, 1] - bboxes[:, 0]\n",
    "        dy = bboxes[:, 3] - bboxes[:, 2]\n",
    "        radii = np.sqrt(dx**2 + dy**2) / 2\n",
    "\n",
    "        return np.array(\n",
    "            [\n",
    "                (bboxes[:, 0] + bboxes[:, 1]) / 2,\n",
    "                (bboxes[:, 2] + bboxes[:, 3]) / 2,\n",
    "                radii,\n",
    "                bboxes[:, 4],\n",
    "            ]\n",
    "        ).T\n",
    "\n",
    "    def run(self, img, gps_sample_corners):\n",
    "        bboxes_pixels = self._get_bboxes_pixels(img)\n",
    "\n",
    "        if len(bboxes_pixels) == 0:\n",
    "            return [], []\n",
    "\n",
    "        bboxes_radial_pixels = self._convert_bbox_to_radial_representation(\n",
    "            bboxes_pixels\n",
    "        )\n",
    "        bboxes_radial_gps = self._bbox_pixels_to_gps(\n",
    "            bboxes_radial_pixels, gps_sample_corners, img.shape\n",
    "        )\n",
    "\n",
    "        return bboxes_radial_gps, bboxes_pixels  # remove the pixels bboxes later\n",
    "\n",
    "\n",
    "class MavlinkInterfaceLayer:\n",
    "    def __init__(self, protos_path=\"protos\"):\n",
    "        self.protos_path = protos_path\n",
    "        self.channel = grpc.insecure_channel(\"localhost:50051\")\n",
    "        self.stub = messaging_pb2_grpc.MessagingServiceStub(self.channel)\n",
    "\n",
    "    def run(self, bboxes):\n",
    "        if len(bboxes) == 0:\n",
    "            return\n",
    "\n",
    "        responses = []\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            encoded_bbox = str(bbox)[1:-1] # remove the brackets\n",
    "            response = self.stub.SendData(messaging_pb2.DataRequest(data=encoded_bbox))\n",
    "            responses.append(response)\n",
    "\n",
    "        return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_center = 29.643946\n",
    "# lon_center = -82.355659\n",
    "\n",
    "# lat_mile = 0.0144927536231884\n",
    "# lon_mile = 0.0181818181818182\n",
    "# lat_min = lat_center - (15 * lat_mile)\n",
    "# lat_max = lat_center + (15 * lat_mile)\n",
    "# lon_min = lon_center - (15 * lon_mile)\n",
    "# lon_max = lon_center + (15 * lon_mile)\n",
    "\n",
    "# DATASET_TOP_LEFT_GPS = np.array((lat_min, lon_min))\n",
    "# DATASET_TOP_RIGHT_GPS = np.array((lat_max, lon_min))\n",
    "# DATASET_BOT_LEFT_GPS = np.array((lat_min, lon_max))\n",
    "# DATASET_BOT_RIGHT_GPS = np.array((lat_max, lon_max))\n",
    "\n",
    "# DATASET_CORNER_GPS_COORDS = np.array(\n",
    "#     [\n",
    "#         DATASET_TOP_LEFT_GPS,\n",
    "#         DATASET_TOP_RIGHT_GPS,\n",
    "#         DATASET_BOT_LEFT_GPS,\n",
    "#         DATASET_BOT_RIGHT_GPS,\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "DATASET_TOP_LEFT_GPS = np.array((12.86308254761559, 77.5151947517078))\n",
    "DATASET_TOP_RIGHT_GPS = np.array((12.863010715187013, 77.52267023737696))\n",
    "DATASET_BOT_LEFT_GPS = np.array((12.859008245256549, 77.5151541499705))\n",
    "DATASET_BOT_RIGHT_GPS = np.array((12.858936436333265, 77.52262951527761))\n",
    "DATASET_CORNER_GPS_COORDS = np.array([DATASET_TOP_LEFT_GPS, DATASET_TOP_RIGHT_GPS, DATASET_BOT_LEFT_GPS, DATASET_BOT_RIGHT_GPS])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure to run `realtime_ui/network.py` on the side first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000, 3)\n",
      "(1000, 1000, 3)\n",
      "(1000, 1000, 3)\n",
      "(1000, 1000, 3)\n",
      "(1000, 1000, 3)\n",
      "(1000, 1000, 3)\n",
      "(1000, 1000, 3)\n",
      "(1000, 1000, 3)\n",
      "(1000, 1000, 3)\n"
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNIMPLEMENTED\n\tdetails = \"Method not found!\"\n\tdebug_error_string = \"{\"created\":\"@1680710509.451407000\",\"description\":\"Error received from peer ipv6:[::1]:50051\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":904,\"grpc_message\":\"Method not found!\",\"grpc_status\":12}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d3275a6341a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbboxes_gps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_corner_gps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmav_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes_gps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes_gps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6811a8fa4877>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, bboxes)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mencoded_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# remove the brackets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessaging_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mresponses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    944\u001b[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     def with_call(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNIMPLEMENTED\n\tdetails = \"Method not found!\"\n\tdebug_error_string = \"{\"created\":\"@1680710509.451407000\",\"description\":\"Error received from peer ipv6:[::1]:50051\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":904,\"grpc_message\":\"Method not found!\",\"grpc_status\":12}\"\n>"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# np.random.seed(40)\n",
    "\n",
    "mock_image_path = \"../realtime_ui/data/demo.png\"\n",
    "\n",
    "img_layer = ImageProcessingLayer(\n",
    "    mock_wait_time=1,\n",
    "    mock_corner_gps_coords=DATASET_CORNER_GPS_COORDS,\n",
    "    mock_image_path=mock_image_path,\n",
    ")\n",
    "\n",
    "# For illustration, show the mock path\n",
    "pathtrace = np.zeros(img_layer._mock_img_full.shape[:2])\n",
    "for pixel in img_layer._path_pixels:\n",
    "    y, x = pixel[:2].astype(int)\n",
    "    pathtrace[x-50:x+50, y-50:y+50] = 1\n",
    "plt.imshow(pathtrace, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "weights_file = \"../raspberry_pi_code/weights/yolov3-aerial.weights\"\n",
    "classes_file = \"../raspberry_pi_code/weights/aerial.names\"\n",
    "config_file = \"../raspberry_pi_code/weights/yolov3-aerial.cfg\"\n",
    "\n",
    "obj_layer = ObjectDetectionLayer(\n",
    "    config_file=config_file, weights_file=weights_file, classes_file=classes_file\n",
    ")\n",
    "\n",
    "mav_layer = MavlinkInterfaceLayer()\n",
    "\n",
    "for img, img_corner_gps in img_layer.run():\n",
    "    print(img.shape)\n",
    "    bboxes_gps, bboxes_pixels = obj_layer.run(img, img_corner_gps)\n",
    "    responses = mav_layer.run(bboxes_gps)\n",
    "\n",
    "    if len(bboxes_gps) != 0 and len(responses) == 0:\n",
    "        print(\"No responses from MAVLink\")\n",
    "        print(bboxes_gps)\n",
    "\n",
    "    if responses:    \n",
    "        print(responses)\n",
    "\n",
    "    # for bbox_gps, bbox_pixels in zip(bboxes_gps, bboxes_pixels):\n",
    "    #     print(bbox_gps, bbox_pixels)\n",
    "    #     plt.imshow(\n",
    "    #         img[bbox_pixels[2] : bbox_pixels[3], bbox_pixels[0] : bbox_pixels[1]]\n",
    "    #     )\n",
    "    #     plt.title(f\"Confidence: {bbox_pixels[4]}\")\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
