{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "sys.path.append(\"./protos\")\n",
    "\n",
    "import grpc\n",
    "import messaging_pb2\n",
    "import messaging_pb2_grpc\n",
    "\n",
    "i = 0\n",
    "\n",
    "def append_to_csv(data):\n",
    "    file_path = \"data/dir/data.csv\"\n",
    "    with open(file_path, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(data)\n",
    "\n",
    "class ImageProcessingLayer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim=(1000, 1000),\n",
    "        mock=True,\n",
    "        mock_image_path=None,\n",
    "        mock_num_samples=10,\n",
    "        mock_wait_time=1,\n",
    "        mock_corner_gps_coords=None,\n",
    "    ):\n",
    "        self.mock = mock\n",
    "\n",
    "        if not mock:\n",
    "            return\n",
    "\n",
    "        self.mock_wait_time = mock_wait_time\n",
    "\n",
    "        if mock_image_path is None:\n",
    "            # mock_image_path = \"data/demo.jpg\"\n",
    "            mock_image_path = \"../data/demo.jpg\"\n",
    "\n",
    "        self._mock_img_full = np.asarray(Image.open(mock_image_path))[:, :, :3]\n",
    "\n",
    "        self._output_dim = output_dim\n",
    "        diag_len = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "        self._gcps_pixels = self._generate_random_gcps(\n",
    "            self._mock_img_full, mock_num_samples, padding=(diag_len, diag_len)\n",
    "        )\n",
    "\n",
    "        self._mock_corner_gps_coords = mock_corner_gps_coords\n",
    "        self._pixel_to_gps_transform = self._dataset_pixel_to_gps_transform(\n",
    "            self._mock_corner_gps_coords\n",
    "        )\n",
    "\n",
    "        self._path_pixels = self._build_path_pixels(self._gcps_pixels)\n",
    "\n",
    "    def _generate_random_gcps(self, img, num_samples, padding=(0, 0)):\n",
    "        return np.random.randint(\n",
    "            padding,\n",
    "            high=(\n",
    "                img.shape[1] - padding[0] - 10,\n",
    "                img.shape[0] - padding[1] - 10,\n",
    "            ),\n",
    "            size=(num_samples, 2),\n",
    "        )\n",
    "\n",
    "    def _build_path_pixels(self, gcps):\n",
    "        STEP_SIZE = 400\n",
    "\n",
    "        delta = np.diff(gcps, axis=0)\n",
    "        directions = delta / np.linalg.norm(delta, axis=1).reshape(-1, 1)\n",
    "        angles = -np.arctan2(directions.T[1], directions.T[0]) * 180 / np.pi\n",
    "        delta_angles = np.append(np.diff(angles), 0)\n",
    "\n",
    "        path = []\n",
    "\n",
    "        for t1, t2, angle, delta_angle in zip(gcps, gcps[1:], angles, delta_angles):\n",
    "            steps = np.linalg.norm(t2 - t1) / STEP_SIZE\n",
    "            line = np.linspace(t1, t2, steps.astype(\"uint32\"), dtype=\"uint32\")\n",
    "            path.extend([np.array([x, y, angle]) for x, y in line])\n",
    "\n",
    "            if delta_angle == 0:\n",
    "                continue\n",
    "\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "\n",
    "            interpolated_angles = np.linspace(angle, angle + delta_angle, 3)\n",
    "            path.extend(\n",
    "                [\n",
    "                    np.array([line[-1][0], line[-1][1], theta])\n",
    "                    for theta in interpolated_angles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return path\n",
    "\n",
    "    def _next_image(self):\n",
    "        if self.mock_wait_time > 0:\n",
    "            time.sleep(self.mock_wait_time)\n",
    "\n",
    "        sample_diag = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "\n",
    "        for x, y, theta in self._path_pixels:\n",
    "            sample = self._crop_around(\n",
    "                self._mock_img_full, (y, x), (sample_diag, sample_diag)\n",
    "            )\n",
    "            \n",
    "            rotated_img = self._center_crop(\n",
    "                rotate(sample, -theta, reshape=False), self._output_dim\n",
    "            )\n",
    "            \n",
    "            theta_radians = theta / 180 * math.pi\n",
    "\n",
    "            center = np.array((x, y))\n",
    "\n",
    "            corner_gps_coords = self._get_corner_gps_coords_of_sample_img(\n",
    "                center, theta_radians\n",
    "            )\n",
    "            \n",
    "            append_to_csv([center[0], center[1], theta]) # append exif data to csv file, center is wrong (needs to be in lat lon instead of pixel)\n",
    "\n",
    "            yield rotated_img, corner_gps_coords\n",
    "\n",
    "    def _crop_around(self, img, center, dim):\n",
    "        dim = np.array(dim).astype(\"uint32\")\n",
    "        x = int(center[1] - dim[1] // 2)\n",
    "        y = int(center[0] - dim[0] // 2)\n",
    "        return img[y : y + dim[0], x : x + dim[1]]\n",
    "\n",
    "    def _center_crop(self, img, dim):\n",
    "        return img[\n",
    "            img.shape[0] // 2 - dim[0] // 2 : img.shape[0] // 2 + dim[0] // 2,\n",
    "            img.shape[1] // 2 - dim[1] // 2 : img.shape[1] // 2 + dim[1] // 2,\n",
    "        ]\n",
    "\n",
    "    def _rotate_vec2d(self, vec2d, radians):\n",
    "        \"\"\"Only rotate a point around the origin (0, 0).\"\"\"\n",
    "        x, y = vec2d\n",
    "        x_new = x * math.cos(radians) - y * math.sin(radians)\n",
    "        y_new = x * math.sin(radians) + y * math.cos(radians)\n",
    "\n",
    "        return np.array([x_new, y_new])\n",
    "\n",
    "    def _rotate_pixel_about_center(self, xy, center, radians):\n",
    "        vector_from_center = np.array(xy) - np.array(center)\n",
    "        return self._rotate_vec2d(vector_from_center, -radians)\n",
    "\n",
    "    def _sample_pixel_to_dataset_pixel_coords(self, xy, sample_center, radians):\n",
    "        # Sample pixel coordinate system has (0,0) at the top left of the sample image\n",
    "        sample_center_in_sample_pixel_coords = (\n",
    "            np.array((self._output_dim[1], self._output_dim[0])) / 2\n",
    "        )\n",
    "        rotated_coords = self._rotate_pixel_about_center(\n",
    "            xy, sample_center_in_sample_pixel_coords, radians\n",
    "        )\n",
    "        return rotated_coords + sample_center\n",
    "\n",
    "    def _sample_pixel_to_gps_coords(self, xy, sample_center, radians):\n",
    "        \"\"\"\n",
    "        sample_center is the center coordinates (np array) of the sample image in the dataset pixel coordinate system\n",
    "        \"\"\"\n",
    "        dataset_pixel_coords = self._sample_pixel_to_dataset_pixel_coords(\n",
    "            xy, sample_center, radians\n",
    "        )\n",
    "        return self._pixel_to_gps_transform(dataset_pixel_coords)\n",
    "\n",
    "    def _get_corner_gps_coords_of_sample_img(self, center, radians):\n",
    "        \"\"\"\n",
    "        center is the center coordinates (np array) of the sample image in the dataset pixel coordinate system\n",
    "        radians is the angle that the sample image coordinate system is rotated relative to the dataset\n",
    "            coordinate system (CCW)\n",
    "        sample_dim is (height, width)\n",
    "        \"\"\"\n",
    "\n",
    "        height, width = self._output_dim\n",
    "\n",
    "        top_left_pixel = np.array((0, 0))\n",
    "        top_right_pixel = np.array((width, 0))\n",
    "        bot_left_pixel = np.array((0, height))\n",
    "        bot_right_pixel = np.array((width, height))\n",
    "\n",
    "        return [\n",
    "            self._sample_pixel_to_gps_coords(corner_pixel, center, radians)\n",
    "            for corner_pixel in [\n",
    "                top_left_pixel,\n",
    "                top_right_pixel,\n",
    "                bot_left_pixel,\n",
    "                bot_right_pixel,\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def _dataset_pixel_to_gps_transform(self, corner_gps_coords):\n",
    "        height, width = self._mock_img_full.shape[:2]\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = corner_gps_coords\n",
    "        right_vec = (top_right_gps - top_left_gps) / width\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / height\n",
    "\n",
    "        transformation = np.array(\n",
    "            [[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]]\n",
    "        )\n",
    "\n",
    "        def transform(pixel):\n",
    "            return transformation @ pixel + top_left_gps\n",
    "\n",
    "        return transform\n",
    "\n",
    "    def run(self, img=None):\n",
    "        if not self.mock:\n",
    "            assert img is not None, \"Image cannot be None\"\n",
    "            return img\n",
    "\n",
    "        return self._next_image()\n",
    "\n",
    "\n",
    "class ObjectDetectionLayer:\n",
    "    def __init__(\n",
    "        self, weights_file=None, classes_file=None, config_file=None, min_confidence=0.3\n",
    "    ):\n",
    "        self.weights_file = weights_file\n",
    "        self.config_file = config_file\n",
    "        self.classes_file = classes_file\n",
    "\n",
    "        self.net = self._load_model()\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "        self.classes = [\"car\", \"truck\", \"bus\", \"minibus\", \"cyclist\"]\n",
    "\n",
    "    def _load_model(self):\n",
    "        return cv2.dnn.readNet(self.weights_file, self.config_file)\n",
    "\n",
    "    def _get_output_layers(self, net):\n",
    "        layer_names = net.getLayerNames()\n",
    "        try:\n",
    "            output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        except:\n",
    "            output_layers = [\n",
    "                layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()\n",
    "            ]\n",
    "\n",
    "        return output_layers\n",
    "\n",
    "    def _get_bboxes_pixels(self, img):\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        Height, Width = image.shape[:2]\n",
    "        scale = 0.00392\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image, scale, (416, 416), (0, 0, 0), True, crop=False\n",
    "        )\n",
    "\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        outs = self.net.forward(self._get_output_layers(self.net))\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.5\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > self.min_confidence:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        bboxes_with_confidence = []\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "            except Exception:\n",
    "                box = boxes[i[0]]\n",
    "\n",
    "            x, y, w, h = [max(v, 0) for v in box[:4]]  # model outputs can be negative\n",
    "\n",
    "            bboxes_with_confidence.append(\n",
    "                np.array((x, x + w, y, y + h, 100 * confidences[i]))\n",
    "            )\n",
    "\n",
    "        # follows the format of x0, x1, y0, y1, confidence\n",
    "        return np.array(bboxes_with_confidence).astype(int)\n",
    "\n",
    "    def _bbox_pixels_to_gps(self, bboxes, gps_corners, img_dim):\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = gps_corners\n",
    "        right_vec = (top_right_gps - top_left_gps) / img_dim[1]\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / img_dim[0]\n",
    "\n",
    "        transformation = np.array(\n",
    "            [[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]]\n",
    "        )\n",
    "\n",
    "        def transform(bbox):\n",
    "            return transformation @ bbox + top_left_gps\n",
    "\n",
    "        return np.array([(*transform(bbox[:2]), *bbox[2:4]) for bbox in bboxes])\n",
    "\n",
    "    # Be careful using this radius. Pixel distance does not convert to latitude and longitude in the same way\n",
    "    def _convert_bbox_to_radial_representation(self, bboxes):\n",
    "        \"\"\"\n",
    "        Given a bbox in the format of x0, x1, y0, y1, confidence.\n",
    "        Returns a bbox in the format of x, y, r, confidence\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Scale by some factor (function of altitude) to convert pixels to meters\n",
    "        dx = bboxes[:, 1] - bboxes[:, 0]\n",
    "        dy = bboxes[:, 3] - bboxes[:, 2]\n",
    "        radii = np.sqrt(dx**2 + dy**2) / 2\n",
    "\n",
    "        return np.array(\n",
    "            [\n",
    "                (bboxes[:, 0] + bboxes[:, 1]) / 2,\n",
    "                (bboxes[:, 2] + bboxes[:, 3]) / 2,\n",
    "                radii,\n",
    "                bboxes[:, 4],\n",
    "            ]\n",
    "        ).T\n",
    "\n",
    "    def run(self, img, gps_sample_corners):\n",
    "        global i\n",
    "        bboxes_pixels = self._get_bboxes_pixels(img)\n",
    "        Image.fromarray(img).convert(\"RGB\").save(f\"data/dir/data_{i}.jpg\")\n",
    "        i = i+ 1\n",
    "\n",
    "        if len(bboxes_pixels) == 0:\n",
    "            return [], []\n",
    "\n",
    "        bboxes_radial_pixels = self._convert_bbox_to_radial_representation(\n",
    "            bboxes_pixels\n",
    "        )\n",
    "        bboxes_radial_gps = self._bbox_pixels_to_gps(\n",
    "            bboxes_radial_pixels, gps_sample_corners, img.shape\n",
    "        )\n",
    "\n",
    "        return bboxes_radial_gps, bboxes_pixels  # remove the pixels bboxes later\n",
    "\n",
    "\n",
    "class MavlinkInterfaceLayer:\n",
    "    def __init__(self, protos_path=\"protos\"):\n",
    "        self.protos_path = protos_path\n",
    "        self.channel = grpc.insecure_channel(\"localhost:50051\")\n",
    "        self.stub = messaging_pb2_grpc.MessagingServiceStub(self.channel)\n",
    "\n",
    "    def run(self, bboxes):\n",
    "        if len(bboxes) == 0:\n",
    "            return\n",
    "\n",
    "        responses = []\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            encoded_bbox = str(bbox)[1:-1] # remove the brackets\n",
    "            response = self.stub.SendData(messaging_pb2.DataRequest(data=encoded_bbox))\n",
    "            responses.append(response)\n",
    "\n",
    "        return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_center = 29.643946\n",
    "# lon_center = -82.355659\n",
    "\n",
    "# lat_mile = 0.0144927536231884\n",
    "# lon_mile = 0.0181818181818182\n",
    "# lat_min = lat_center - (15 * lat_mile)\n",
    "# lat_max = lat_center + (15 * lat_mile)\n",
    "# lon_min = lon_center - (15 * lon_mile)\n",
    "# lon_max = lon_center + (15 * lon_mile)\n",
    "\n",
    "# DATASET_TOP_LEFT_GPS = np.array((lat_min, lon_min))\n",
    "# DATASET_TOP_RIGHT_GPS = np.array((lat_max, lon_min))\n",
    "# DATASET_BOT_LEFT_GPS = np.array((lat_min, lon_max))\n",
    "# DATASET_BOT_RIGHT_GPS = np.array((lat_max, lon_max))\n",
    "\n",
    "# DATASET_CORNER_GPS_COORDS = np.array(\n",
    "#     [\n",
    "#         DATASET_TOP_LEFT_GPS,\n",
    "#         DATASET_TOP_RIGHT_GPS,\n",
    "#         DATASET_BOT_LEFT_GPS,\n",
    "#         DATASET_BOT_RIGHT_GPS,\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "DATASET_TOP_LEFT_GPS = np.array((12.86308254761559, 77.5151947517078))\n",
    "DATASET_TOP_RIGHT_GPS = np.array((12.863010715187013, 77.52267023737696))\n",
    "DATASET_BOT_LEFT_GPS = np.array((12.859008245256549, 77.5151541499705))\n",
    "DATASET_BOT_RIGHT_GPS = np.array((12.858936436333265, 77.52262951527761))\n",
    "DATASET_CORNER_GPS_COORDS = np.array([DATASET_TOP_LEFT_GPS, DATASET_TOP_RIGHT_GPS, DATASET_BOT_LEFT_GPS, DATASET_BOT_RIGHT_GPS])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure to run `realtime_ui/network.py` on the side first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   96  925 1000   60]]\n",
      "[[ 772  821  417  446   98]\n",
      " [ 987 1001  421  455   80]\n",
      " [ 439  494  390  420   52]]\n",
      "[[485 530 421 450  97]\n",
      " [276 328 416 449  91]]\n",
      "[[  0  44 420 452  52]]\n",
      "[[624 707 164 197  86]\n",
      " [626 708 144 182  58]]\n",
      "[[633 678 349 397  90]\n",
      " [678 715 324 360  79]\n",
      " [734 777 267 321  77]]\n",
      "[[495 526  77  98  86]\n",
      " [178 220 318 365  61]]\n",
      "[[457 606 889 999  90]]\n",
      "[[673 756 307 332  96]\n",
      " [653 796 186 287  89]]\n",
      "[[119 238 495 533  69]\n",
      " [691 695  27  39  61]\n",
      " [252 353   0  64  50]]\n",
      "[[119 238 495 533  69]\n",
      " [691 695  27  39  61]\n",
      " [252 353   0  64  50]]\n",
      "[[422 554 171 317  85]]\n",
      "[[520 665 571 705  54]]\n",
      "[[520 665 571 705  54]]\n",
      "[[262 279  77 103  55]\n",
      " [101 109  28  33  53]]\n",
      "[[908 944 913 962  76]]\n",
      "[[634 678 225 278  98]\n",
      " [628 671 480 530  86]\n",
      " [459 495 913 960  78]\n",
      " [722 756 430 461  68]\n",
      " [449 481 238 258  67]]\n",
      "[[187 229 225 281  99]\n",
      " [692 783 693 812  79]\n",
      " [184 226 479 531  77]\n",
      " [735 743 331 350  75]\n",
      " [757 803 658 715  73]\n",
      " [908 942 237 280  71]]\n",
      "[[913 949  31  69  99]\n",
      " [527 571 417 476  82]\n",
      " [484 528 660 716  79]\n",
      " [398 439 308 371  77]\n",
      " [553 625 257 350  71]\n",
      " [832 885 234 312  71]\n",
      " [310 356 658 716  70]\n",
      " [253 336 681 809  64]]\n",
      "[[624 667 155 202  99]\n",
      " [465 500  33  69  99]\n",
      " [333 372 863 891  71]\n",
      " [864 909 374 430  71]]\n",
      "[[175 218 154 201  99]\n",
      " [ 17  52  33  68  97]\n",
      " [  0 136 487 625  76]\n",
      " [306 354 930 971  72]\n",
      " [420 458 382 427  62]]\n",
      "[[893 932   0  23  96]]\n",
      "[[434 473   0  22  96]\n",
      " [713 757 159 201  92]\n",
      " [897 940 254 299  85]]\n",
      "[[256 301 158 201  94]\n",
      " [  0  19   0  25  80]\n",
      " [441 483 255 299  71]]\n",
      "[[256 301 158 201  94]\n",
      " [  0  19   0  25  80]\n",
      " [441 483 255 299  71]]\n",
      "[[443 484  88 136  99]\n",
      " [561 594 264 309  76]]\n",
      "[[650 669 129 162  99]\n",
      " [661 679 339 368  99]\n",
      " [891 979 772 810  75]]\n",
      "[[161 205 309 354  97]\n",
      " [331 374 424 471  70]]\n",
      "[[361 399  10  32  61]\n",
      " [308 325  91 107  61]]\n",
      "[[669 682 698 746  71]\n",
      " [ 82 191 418 541  66]\n",
      " [662 680 741 784  57]\n",
      " [  4  18  10  34  50]]\n",
      "[[179 201 161 191  55]]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(40)\n",
    "\n",
    "mock_image_path = \"../realtime_ui/data/Copy of Blore_Clean.tif\"\n",
    "\n",
    "img_layer = ImageProcessingLayer(\n",
    "    mock_wait_time=1,\n",
    "    mock_corner_gps_coords=DATASET_CORNER_GPS_COORDS,\n",
    "    mock_image_path=mock_image_path,\n",
    ")\n",
    "\n",
    "# For illustration, show the mock path\n",
    "pathtrace = np.zeros(img_layer._mock_img_full.shape[:2])\n",
    "for pixel in img_layer._path_pixels:\n",
    "    y, x = pixel[:2].astype(int)\n",
    "    pathtrace[x-50:x+50, y-50:y+50] = 1\n",
    "plt.imshow(pathtrace, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "weights_file = \"../raspberry_pi_code/weights/yolov3-aerial.weights\"\n",
    "classes_file = \"../raspberry_pi_code/weights/aerial.names\"\n",
    "config_file = \"../raspberry_pi_code/weights/yolov3-aerial.cfg\"\n",
    "\n",
    "obj_layer = ObjectDetectionLayer(\n",
    "    config_file=config_file, weights_file=weights_file, classes_file=classes_file\n",
    ")\n",
    "\n",
    "mav_layer = MavlinkInterfaceLayer()\n",
    "\n",
    "for img, img_corner_gps in img_layer.run():\n",
    "    bboxes_gps, bboxes_pixels = obj_layer.run(img, img_corner_gps)\n",
    "    responses = mav_layer.run(bboxes_gps)\n",
    "\n",
    "    if len(bboxes_gps) != 0 and len(responses) == 0:\n",
    "        print(\"No responses from MAVLink\")\n",
    "\n",
    "    if responses:    \n",
    "        print(bboxes_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
