{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "\n",
    "mmcv.collect_env()\n",
    "\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmdet.apis import inference_detector\n",
    "from mmrotate.models import build_detector\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(\"./protos\")\n",
    "\n",
    "import grpc\n",
    "# import messaging_pb2\n",
    "# import messaging_pb2_grpc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import math\n",
    "\n",
    "class ImageProcessingLayer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim=(1000, 1000),\n",
    "        mock=True,\n",
    "        mock_image_path=None,\n",
    "        mock_num_samples=10,\n",
    "        mock_wait_time=1,\n",
    "        mock_corner_gps_coords=None,\n",
    "    ):\n",
    "        self.mock = mock\n",
    "\n",
    "        if not mock:\n",
    "            return\n",
    "\n",
    "        self.mock_wait_time = mock_wait_time\n",
    "\n",
    "        if mock_image_path is None:\n",
    "            # mock_image_path = \"data/demo.jpg\"\n",
    "            mock_image_path = \"../data/demo.jpg\"\n",
    "\n",
    "\n",
    "        self._mock_img_full = np.asarray(Image.open(mock_image_path))[:, :, :3]\n",
    "\n",
    "        self._output_dim = output_dim\n",
    "        diag_len = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "        # self._gcps_pixels = self._generate_random_gcps(\n",
    "        #     self._mock_img_full, mock_num_samples, padding=(diag_len, diag_len)\n",
    "        # )\n",
    "        self._gcps_pixels = np.array([(8000, 3000), (9000, 3000), (9000, 4000), (11000, 5000)])\n",
    "\n",
    "\n",
    "        self._mock_corner_gps_coords = mock_corner_gps_coords\n",
    "        self._pixel_to_gps_transform = self._dataset_pixel_to_gps_transform(self._mock_corner_gps_coords)\n",
    "\n",
    "        self._path_pixels = self._build_path_pixels(self._gcps_pixels)\n",
    "\n",
    "    def _generate_random_gcps(self, img, num_samples, padding=(0, 0)):\n",
    "        return np.random.randint(\n",
    "            padding,\n",
    "            high=(img.shape[1] - padding[0], img.shape[0] - padding[1]),\n",
    "            size=(num_samples, 2),\n",
    "        )\n",
    "\n",
    "    def _build_path_pixels(self, gcps):\n",
    "        STEP_SIZE = 400\n",
    "        \n",
    "        delta = np.diff(gcps, axis=0)\n",
    "        directions = delta / np.linalg.norm(delta, axis=1).reshape(-1, 1)\n",
    "        angles = -np.arctan2(directions.T[1], directions.T[0]) * 180 / np.pi\n",
    "        delta_angles = np.append(np.diff(angles), 0)\n",
    "\n",
    "        path = []\n",
    "\n",
    "        for t1, t2, angle, delta_angle in zip(gcps, gcps[1:], angles, delta_angles):\n",
    "            steps = np.linalg.norm(t2 - t1) / STEP_SIZE\n",
    "            line = np.linspace(t1, t2, steps.astype(\"uint32\"), dtype=\"uint32\")\n",
    "            path.extend([np.array([x, y, angle]) for x, y in line])\n",
    "\n",
    "            if delta_angle == 0:\n",
    "                continue\n",
    "\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "\n",
    "            interpolated_angles = np.linspace(angle, angle + delta_angle, 3)\n",
    "            path.extend(\n",
    "                [\n",
    "                    np.array([line[-1][0], line[-1][1], theta])\n",
    "                    for theta in interpolated_angles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return path\n",
    "\n",
    "    def _next_image(self):\n",
    "        if self.mock_wait_time > 0:\n",
    "            time.sleep(self.mock_wait_time)\n",
    "\n",
    "        sample_diag = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "\n",
    "        for x, y, theta in self._path_pixels:\n",
    "            sample = self._crop_around(\n",
    "                self._mock_img_full, (y, x), (sample_diag, sample_diag)\n",
    "            )\n",
    "            rotated_img = self._center_crop(\n",
    "                rotate(sample, -theta, reshape=False), self._output_dim\n",
    "            )\n",
    "          \n",
    "            theta_radians = theta / 180 * math.pi\n",
    "            \n",
    "            center = np.array((x, y))\n",
    "            \n",
    "            corner_gps_coords = self._get_corner_gps_coords_of_sample_img(center, theta_radians)\n",
    "            \n",
    "            yield rotated_img, corner_gps_coords\n",
    "\n",
    "    def _crop_around(self, img, center, dim):\n",
    "        dim = np.array(dim).astype(\"uint32\")\n",
    "        x = int(center[1] - dim[1] // 2)\n",
    "        y = int(center[0] - dim[0] // 2)\n",
    "        return img[y : y + dim[0], x : x + dim[1]]\n",
    "\n",
    "    def _center_crop(self, img, dim):\n",
    "        return img[\n",
    "            img.shape[0] // 2 - dim[0] // 2 : img.shape[0] // 2 + dim[0] // 2,\n",
    "            img.shape[1] // 2 - dim[1] // 2 : img.shape[1] // 2 + dim[1] // 2,\n",
    "        ]\n",
    "\n",
    "    def _rotate_vec2d(self, vec2d, radians):\n",
    "        \"\"\"Only rotate a point around the origin (0, 0).\"\"\"\n",
    "        x, y = vec2d\n",
    "        x_new = x * math.cos(radians) - y * math.sin(radians)\n",
    "        y_new = x * math.sin(radians) + y * math.cos(radians)\n",
    "\n",
    "        return np.array([x_new, y_new])\n",
    "\n",
    "    def _rotate_pixel_about_center(self, xy, center, radians):\n",
    "        vector_from_center = np.array(xy) - np.array(center)\n",
    "        return self._rotate_vec2d(vector_from_center, -radians)\n",
    "\n",
    "    def _sample_pixel_to_dataset_pixel_coords(self, xy, sample_center, radians):\n",
    "        # Sample pixel coordinate system has (0,0) at the top left of the sample image\n",
    "        sample_center_in_sample_pixel_coords = np.array((self._output_dim[1], self._output_dim[0])) / 2\n",
    "        rotated_coords = self._rotate_pixel_about_center(xy, sample_center_in_sample_pixel_coords, radians)\n",
    "        coords = rotated_coords + sample_center\n",
    "        return coords\n",
    "\n",
    "    def _sample_pixel_to_gps_coords(self, xy, sample_center, radians):\n",
    "        \"\"\"\n",
    "            sample_center is the center coordinates (np array) of the sample image in the dataset pixel coordinate system\n",
    "        \"\"\"\n",
    "        dataset_pixel_coords = self._sample_pixel_to_dataset_pixel_coords(xy, sample_center, radians)\n",
    "        return self._pixel_to_gps_transform(dataset_pixel_coords)\n",
    "        \n",
    "    def _get_corner_gps_coords_of_sample_img(self, center, radians):\n",
    "        \"\"\"\n",
    "            center is the center coordinates (np array) of the sample image in the dataset pixel coordinate system\n",
    "            radians is the angle that the sample image coordinate system is rotated relative to the dataset\n",
    "                coordinate system (CCW)\n",
    "            sample_dim is (height, width)\n",
    "        \"\"\"\n",
    "\n",
    "        height, width = self._output_dim\n",
    "        \n",
    "        top_left_pixel = np.array((0,0))\n",
    "        top_right_pixel = np.array((width,0))\n",
    "        bot_left_pixel = np.array((0,height))\n",
    "        bot_right_pixel = np.array((width,height))\n",
    "        \n",
    "        return [\n",
    "            self._sample_pixel_to_gps_coords(corner_pixel, center, radians)\n",
    "            for corner_pixel in [top_left_pixel, top_right_pixel, bot_left_pixel, bot_right_pixel]\n",
    "        ]\n",
    "\n",
    "    def _dataset_pixel_to_gps_transform(self, corner_gps_coords):\n",
    "        height, width = self._mock_img_full.shape[:2]\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = corner_gps_coords\n",
    "        right_vec = (top_right_gps - top_left_gps) / width\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / height\n",
    "\n",
    "        transformation = np.array([[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]])\n",
    "        \n",
    "        def transform(pixel):\n",
    "            return transformation @ pixel + top_left_gps\n",
    "        \n",
    "        return transform\n",
    "\n",
    "    def run(self, img=None):\n",
    "        if not self.mock:\n",
    "            assert img is not None, \"Image cannot be None\"\n",
    "            return img\n",
    "\n",
    "        return self._next_image()\n",
    "\n",
    "\n",
    "# class ObjectDetectionLayer:\n",
    "#     def __init__(\n",
    "#         self, config_file=None, checkpoint_file=None, device=torch.device('cpu'), min_confidence=0.3\n",
    "#     ):\n",
    "#         if config_file is None:\n",
    "#             config_file = \"examples/oriented_rcnn_r50_fpn_1x_dota_le90.py\"\n",
    "#         if checkpoint_file is None:\n",
    "#             checkpoint_file = \"examples/oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth\"\n",
    "\n",
    "#         self.config_file = config_file\n",
    "#         self.checkpoint_file = checkpoint_file\n",
    "#         self.device = device\n",
    "\n",
    "#         self.model = self._load_model()\n",
    "#         self.min_confidence = min_confidence\n",
    "\n",
    "#     def _load_model(self):\n",
    "#         config = mmcv.Config.fromfile(self.config_file)\n",
    "#         config.model.pretrained = None\n",
    "\n",
    "#         model = build_detector(config.model)\n",
    "#         checkpoint = load_checkpoint(\n",
    "#             model, self.checkpoint_file, map_location=self.device\n",
    "#         )\n",
    "\n",
    "#         model.CLASSES = checkpoint[\"meta\"][\"CLASSES\"]\n",
    "#         model.cfg = config\n",
    "#         model.to(self.device)\n",
    "#         model = model.eval()\n",
    "\n",
    "#         return model\n",
    "\n",
    "#     def _get_bboxes_pixels(self, img):\n",
    "#         padded_img = np.zeros((max(img.shape[0], 1024), max(img.shape[1], 1024), 3))\n",
    "#         padded_img[: img.shape[0], : img.shape[1]] = img\n",
    "\n",
    "#         vehicle_classes = [\n",
    "#             i for i, c in enumerate(self.model.CLASSES) if \"vehicle\" in c\n",
    "#         ]\n",
    "\n",
    "#         inference = inference_detector(self.model, padded_img)\n",
    "#         bboxes = [inference[index] for index in vehicle_classes]\n",
    "\n",
    "#         bboxes = np.concatenate(bboxes, axis=0)\n",
    "#         bboxes = bboxes[bboxes[:, 5] > self.min_confidence]\n",
    "\n",
    "#         # the bboxes are in a weird polygonal format, so we convert them to rectangles\n",
    "#         rect_bboxes = (\n",
    "#             np.array(\n",
    "#                 [\n",
    "#                     bboxes[:, 1] - bboxes[:, 2] // 2,\n",
    "#                     bboxes[:, 1] + bboxes[:, 2] // 2,\n",
    "#                     bboxes[:, 0] - bboxes[:, 2] // 2,\n",
    "#                     bboxes[:, 0] + bboxes[:, 3],\n",
    "#                     100 * bboxes[:, -1],  # confidence score\n",
    "#                 ]\n",
    "#             )\n",
    "#             .astype(int)\n",
    "#             .T\n",
    "#         )\n",
    "\n",
    "#         # follows the format of x0, x1, y0, y1, confidence\n",
    "#         return rect_bboxes\n",
    "\n",
    "#     def _bbox_pixels_to_gps(self, bboxes, gps_corners, img_dim):\n",
    "#         top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = gps_corners\n",
    "#         right_vec = (top_right_gps - top_left_gps) / img_dim[1]\n",
    "#         bot_vec = (bot_left_gps - top_left_gps) / img_dim[0]\n",
    "\n",
    "#         transformation = np.array([[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]])\n",
    "\n",
    "#         def transform(bbox):\n",
    "#             return transformation @ bbox + top_left_gps\n",
    "            \n",
    "#         return np.array([transform(bbox) for bbox in bboxes])\n",
    "    \n",
    "#     def _convert_bbox_to_radial_representation(self, bboxes):\n",
    "#         \"\"\"\n",
    "#             Given a bbox in the format of x0, x1, y0, y1, confidence.\n",
    "#             Returns a bbox in the format of x, y, r, confidence\n",
    "#         \"\"\"\n",
    "\n",
    "#         radii = np.sqrt((bboxes[:, 1] - bboxes[:, 0]) ** 2 + (bboxes[:, 3] - bboxes[:, 2]) ** 2)\n",
    "\n",
    "#         return np.array([\n",
    "#             (bboxes[:, 0] + bboxes[:, 1]) / 2,\n",
    "#             (bboxes[:, 2] + bboxes[:, 3]) / 2,\n",
    "#             radii,\n",
    "#             bboxes[:, 4]\n",
    "#         ]).T\n",
    "\n",
    "#     def run(self, img, gps_sample_corners):\n",
    "#         bboxes_pixels = self._get_bboxes_pixels(img)\n",
    "\n",
    "#         if len(bboxes_pixels) == 0:\n",
    "#             return [], []\n",
    "\n",
    "#         bboxes_radial_pixels = self._convert_bbox_to_radial_representation(bboxes_pixels)\n",
    "#         bboxes_radial_gps = self._bbox_pixels_to_gps(bboxes_radial_pixels[:, :2], gps_sample_corners, img.shape)\n",
    "#         return bboxes_radial_gps, bboxes_pixels  # remove the pixels bboxes later\n",
    "\n",
    "\n",
    "    \n",
    "class OpenCVObjectDetectionLayer:\n",
    "    def __init__(\n",
    "        self, weights_file=None, classes_file=None, config_file=None, device=torch.device('cpu'), min_confidence=0.3\n",
    "    ):\n",
    "#         if config_file is None:\n",
    "#             config_file = \"examples/oriented_rcnn_r50_fpn_1x_dota_le90.py\"\n",
    "#         if checkpoint_file is None:\n",
    "#             checkpoint_file = \"examples/oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth\"\n",
    "\n",
    "        self.weights_file = weights_file\n",
    "        self.config_file = config_file\n",
    "        self.classes_file = classes_file\n",
    "        self.device = device\n",
    "\n",
    "        self.net = self._load_model()\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "    def _load_model(self):\n",
    "        net = cv2.dnn.readNet(self.weights_file, self.config_file)\n",
    "        return net\n",
    "\n",
    "    def _get_output_layers(self, net):\n",
    "        layer_names = net.getLayerNames()\n",
    "        try:\n",
    "            output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        except:\n",
    "            output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "        return output_layers\n",
    "\n",
    "    def _get_bboxes_pixels(self, img):\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        Width = image.shape[1]\n",
    "        Height = image.shape[0]\n",
    "        scale = 0.00392\n",
    "\n",
    "        classes = None\n",
    "\n",
    "        \n",
    "        with open(self.classes_file, 'r') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        outs = self.net.forward(self._get_output_layers(self.net))\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.5\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "\n",
    "        bboxes_with_confidence = []\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "\n",
    "            except:\n",
    "                i = i[0]\n",
    "                box = boxes[i]\n",
    "\n",
    "\n",
    "            x = box[0]\n",
    "            y = box[1]\n",
    "            w = box[2]\n",
    "            h = box[3]\n",
    "            \n",
    "            # HACK: Coordinates are sometimes negative. Fix this\n",
    "            if x < 0:\n",
    "                x = 0\n",
    "            if y < 0:\n",
    "                y = 0\n",
    "            \n",
    "            bboxes_with_confidence.append(np.array((x, x+w, y, y+h, 100*confidences[i])))\n",
    "            \n",
    "        # follows the format of x0, x1, y0, y1, confidence\n",
    "        return np.array(bboxes_with_confidence).astype(int)\n",
    "\n",
    "    def _bbox_pixels_to_gps(self, bboxes, gps_corners, img_dim):\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = gps_corners\n",
    "        right_vec = (top_right_gps - top_left_gps) / img_dim[1]\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / img_dim[0]\n",
    "\n",
    "        transformation = np.array([[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]])\n",
    "\n",
    "        def transform(bbox):\n",
    "            return transformation @ bbox + top_left_gps\n",
    "            \n",
    "        return np.array([transform(bbox) for bbox in bboxes])\n",
    "    \n",
    "    # Be careful using this radius. Pixel distance does not convert to latitude and longitude in the same way\n",
    "    def _convert_bbox_to_radial_representation(self, bboxes):\n",
    "        \"\"\"\n",
    "            Given a bbox in the format of x0, x1, y0, y1, confidence.\n",
    "            Returns a bbox in the format of x, y, r, confidence\n",
    "        \"\"\"\n",
    "\n",
    "        radii = np.sqrt((bboxes[:, 1] - bboxes[:, 0]) ** 2 + (bboxes[:, 3] - bboxes[:, 2]) ** 2)\n",
    "\n",
    "        return np.array([\n",
    "            (bboxes[:, 0] + bboxes[:, 1]) / 2,\n",
    "            (bboxes[:, 2] + bboxes[:, 3]) / 2,\n",
    "            radii,\n",
    "            bboxes[:, 4]\n",
    "        ]).T\n",
    "\n",
    "    def run(self, img, gps_sample_corners):\n",
    "        bboxes_pixels = self._get_bboxes_pixels(img)\n",
    "\n",
    "        if len(bboxes_pixels) == 0:\n",
    "            return [], []\n",
    "        bboxes_radial_pixels = self._convert_bbox_to_radial_representation(bboxes_pixels)\n",
    "        bboxes_radial_gps = self._bbox_pixels_to_gps(bboxes_radial_pixels[:, :2], gps_sample_corners, img.shape)\n",
    "\n",
    "        return bboxes_radial_gps, bboxes_pixels  # remove the pixels bboxes later\n",
    "    \n",
    "\n",
    "class MavlinkInterfaceLayer:\n",
    "    def __init__(self, protos_path=\"protos\"):\n",
    "        self.protos_path = protos_path\n",
    "        self.channel = grpc.insecure_channel(\"localhost:50051\")\n",
    "        self.stub = messaging_pb2_grpc.MessagingServiceStub(self.channel)\n",
    "        pass\n",
    "\n",
    "    def run(self, bboxes):\n",
    "        if len(bboxes) == 0:\n",
    "            return\n",
    "\n",
    "        print(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_center = 29.643946\n",
    "lon_center = -82.355659\n",
    "\n",
    "lat_mile = 0.0144927536231884\n",
    "lon_mile = 0.0181818181818182\n",
    "lat_min = lat_center - (15 * lat_mile)\n",
    "lat_max = lat_center + (15 * lat_mile)\n",
    "lon_min = lon_center - (15 * lon_mile)\n",
    "lon_max = lon_center + (15 * lon_mile)\n",
    "\n",
    "DATASET_TOP_LEFT_GPS = np.array((lat_min, lon_min))\n",
    "DATASET_TOP_RIGHT_GPS = np.array((lat_max, lon_min))\n",
    "DATASET_BOT_LEFT_GPS = np.array((lat_min, lon_max))\n",
    "DATASET_BOT_RIGHT_GPS = np.array((lat_max, lon_max))\n",
    "\n",
    "DATASET_CORNER_GPS_COORDS = np.array([DATASET_TOP_LEFT_GPS, DATASET_TOP_RIGHT_GPS, DATASET_BOT_LEFT_GPS, DATASET_BOT_RIGHT_GPS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29.6629 -82.3965]\n",
      "[ 29.6705 -82.3926]\n",
      "[ 29.713  -82.4436]\n",
      "[ 29.7122 -82.4342]\n",
      "[ 29.7072 -82.3504]\n",
      "[ 29.7072 -82.3504]\n",
      "[ 29.7071 -82.3504]\n",
      "[ 29.7247 -82.3335]\n",
      "[ 29.744  -82.3202]\n",
      "[ 29.744  -82.3202]\n",
      "[ 29.7463 -82.2944]\n",
      "[ 29.7694 -82.2906]\n",
      "[ 29.7724 -82.2927]\n",
      "[ 29.7783 -82.2878]\n"
     ]
    }
   ],
   "source": [
    "mock_image_path = \"../data/demo.jpg\"\n",
    "\n",
    "img_layer = ImageProcessingLayer(mock_wait_time=1, mock_corner_gps_coords=DATASET_CORNER_GPS_COORDS,\n",
    "                                 mock_image_path=mock_image_path)\n",
    "\n",
    "weights_file = \"/home/matt/RT-Flight/yolo-test/yolov3-aerial.weights\"\n",
    "classes_file = \"/home/matt/RT-Flight/yolo-test/aerial-darknet/data/aerial.names\"\n",
    "config_file = \"/home/matt/RT-Flight/yolo-test/aerial-darknet/cfg/yolov3-aerial.cfg\"\n",
    "\n",
    "obj_layer = OpenCVObjectDetectionLayer(config_file=config_file, weights_file=weights_file,\n",
    "                                       classes_file=classes_file, device='cpu')\n",
    "\n",
    "# mav_layer = MavlinkInterfaceLayer()\n",
    "\n",
    "for img, img_corner_gps in img_layer.run():\n",
    "    bboxes_gps, bboxes_pixels = obj_layer.run(img, img_corner_gps)\n",
    "#     mav_layer.run(bboxes)\n",
    "\n",
    "    for bbox_gps in bboxes_gps:\n",
    "        output = str(bbox_gps)\n",
    "        print(output)\n",
    "        \n",
    "#         response = mav_layer.stub.SendData(messaging_pb2.DataRequest(data=output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
