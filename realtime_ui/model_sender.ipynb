{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/RT-Flight/testing/RT-env/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "\n",
    "mmcv.collect_env()\n",
    "\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmdet.apis import inference_detector\n",
    "from mmrotate.models import build_detector\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(\"./protos\")\n",
    "\n",
    "import grpc\n",
    "# import messaging_pb2\n",
    "# import messaging_pb2_grpc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "\n",
    "class ImageProcessingLayer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        mock=True,\n",
    "        mock_image_path=None,\n",
    "        mock_num_samples=10,\n",
    "        mock_wait_time=1,\n",
    "    ):\n",
    "        self.mock = mock\n",
    "\n",
    "        if not mock:\n",
    "            return\n",
    "\n",
    "        self.mock_wait_time = mock_wait_time\n",
    "\n",
    "        if mock_image_path is None:\n",
    "            mock_image_path = \"../data/demo.jpg\" #jpg matters\n",
    "\n",
    "        self._mock_img_full = np.asarray(Image.open(mock_image_path))\n",
    "        self._output_dim = (1000, 1000)\n",
    "        diag_len = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "#         self._gcps_pixels = self._generate_random_gcps(\n",
    "#             self._mock_img_full, mock_num_samples, padding=(diag_len, diag_len)\n",
    "#         )\n",
    "\n",
    "        self._gcps_pixels = np.array([(8000, 3000), (9000, 3000), (9000, 4000), (11000, 5000)])\n",
    "        \n",
    "        # maybe convert from pixels to lat/lon here\n",
    "\n",
    "        self._path_pixels = self._build_path_pixels(self._gcps_pixels)\n",
    "\n",
    "    def _generate_random_gcps(self, img, num_samples, padding=(0, 0)):\n",
    "        return np.random.randint(\n",
    "            padding,\n",
    "            high=(img.shape[0] - padding[0], img.shape[1] - padding[1]),\n",
    "            size=(num_samples, 2),\n",
    "        )\n",
    "\n",
    "    def _build_path_pixels(self, gcps):\n",
    "        delta = np.diff(gcps, axis=0)\n",
    "        directions = delta / np.linalg.norm(delta, axis=1).reshape(-1, 1)\n",
    "        angles = np.arctan2(directions.T[1], directions.T[0]) * 180 / np.pi\n",
    "        delta_angles = np.append(np.diff(angles), 0)\n",
    "\n",
    "        path = []\n",
    "\n",
    "        for t1, t2, angle, delta_angle in zip(gcps, gcps[1:], angles, delta_angles):\n",
    "            steps = np.linalg.norm(t2 - t1) / 90\n",
    "            line = np.linspace(t1, t2, steps.astype(\"uint32\"), dtype=\"uint32\")\n",
    "            path.extend([np.array([x, y, angle]) for x, y in line])\n",
    "\n",
    "            if delta_angle == 0:\n",
    "                continue\n",
    "\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "\n",
    "            interpolated_angles = np.linspace(angle, angle + delta_angle, 3)\n",
    "            path.extend(\n",
    "                [\n",
    "                    np.array([line[-1][0], line[-1][1], theta])\n",
    "                    for theta in interpolated_angles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return path\n",
    "\n",
    "    def _next_image(self):\n",
    "        if self.mock_wait_time > 0:\n",
    "            time.sleep(self.mock_wait_time)\n",
    "\n",
    "        sample_diag = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "\n",
    "        for x, y, theta in self._path_pixels:\n",
    "            sample = self._crop_around(\n",
    "                self._mock_img_full, (y, x), (sample_diag, sample_diag)\n",
    "            )\n",
    "            rotated_img = self._center_crop(\n",
    "                rotate(sample, -theta, reshape=False), self._output_dim\n",
    "            )\n",
    "            yield rotated_img\n",
    "\n",
    "    def _crop_around(self, img, center, dim):\n",
    "        dim = np.array(dim).astype(\"uint32\")\n",
    "        x = int(center[1] - dim[1] // 2)\n",
    "        y = int(center[0] - dim[0] // 2)\n",
    "        return img[y : y + dim[0], x : x + dim[1]]\n",
    "\n",
    "    def _center_crop(self, img, dim):\n",
    "        return img[\n",
    "            img.shape[0] // 2 - dim[0] // 2 : img.shape[0] // 2 + dim[0] // 2,\n",
    "            img.shape[1] // 2 - dim[1] // 2 : img.shape[1] // 2 + dim[1] // 2,\n",
    "        ]\n",
    "\n",
    "    def run(self, img=None):\n",
    "        if not self.mock:\n",
    "            assert img is not None, \"Image cannot be None\"\n",
    "            return img\n",
    "\n",
    "        return self._next_image()\n",
    "\n",
    "\n",
    "class ObjectDetectionLayer:\n",
    "    def __init__(\n",
    "        self, config_file=None, checkpoint_file=None, device=\"cuda\", min_confidence=0.3\n",
    "    ):\n",
    "        if config_file is None:\n",
    "            config_file = \"../examples/oriented_rcnn_r50_fpn_1x_dota_le90.py\"\n",
    "        if checkpoint_file is None:\n",
    "            checkpoint_file = \"../examples/oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth\"\n",
    "\n",
    "        self.config_file = config_file\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.device = device\n",
    "\n",
    "        self.model = self._load_model()\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "    def _load_model(self):\n",
    "        \n",
    "        config = mmcv.Config.fromfile(self.config_file)\n",
    "        config.model.pretrained = None\n",
    "\n",
    "        model = build_detector(config.model)\n",
    "        checkpoint = load_checkpoint(\n",
    "            model, self.checkpoint_file, map_location=self.device\n",
    "        )\n",
    "\n",
    "        model.CLASSES = checkpoint[\"meta\"][\"CLASSES\"]\n",
    "        model.cfg = config\n",
    "        model.to(self.device)\n",
    "        model = model.eval()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def _get_bboxes_pixels(self, img):\n",
    "        vehicle_classes = [\n",
    "            i for i, c in enumerate(self.model.CLASSES) if \"vehicle\" in c\n",
    "        ]\n",
    "        inference = inference_detector(self.model, img)\n",
    "        bboxes = [inference[index] for index in vehicle_classes]\n",
    "\n",
    "        bboxes = np.concatenate(bboxes, axis=0)\n",
    "        bboxes = bboxes[bboxes[:, 5] > self.min_confidence]\n",
    "\n",
    "        # the bboxes are in a weird polygonal format, so we convert them to rectangles\n",
    "        rect_bboxes = (\n",
    "            np.array(\n",
    "                [\n",
    "                    bboxes[:, 1] - bboxes[:, 2] // 2,\n",
    "                    bboxes[:, 1] + bboxes[:, 2] // 2,\n",
    "                    bboxes[:, 0] - bboxes[:, 2] // 2,\n",
    "                    bboxes[:, 0] + bboxes[:, 3],\n",
    "                    100 * bboxes[:, -1],  # confidence score\n",
    "                ]\n",
    "            )\n",
    "            .astype(int)\n",
    "            .T\n",
    "        )\n",
    "\n",
    "        # follows the format of x0, x1, y0, y1, confidence\n",
    "        return rect_bboxes\n",
    "\n",
    "    def run(self, img):\n",
    "        result = self._get_bboxes_pixels(img)\n",
    "\n",
    "        # convert pixels to lat/lon here\n",
    "        return result\n",
    "\n",
    "    \n",
    "    \n",
    "def get_output_layers(net):\n",
    "    \n",
    "    layer_names = net.getLayerNames()\n",
    "    try:\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except:\n",
    "        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = COLORS[class_id]\n",
    "\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    \n",
    "class OpenCVObjectDetectionLayer:\n",
    "    def __init__(\n",
    "        self, config_file=None, weights_file=None, classes_file = None, device=torch.device('cpu'), min_confidence=0.3\n",
    "    ):\n",
    "        self.config_file = config_file\n",
    "        self.weights_file = weights_file\n",
    "        self.classes_file = classes_file\n",
    "        self.device = device\n",
    "\n",
    "        self.net = self._load_model()\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "    def _load_model(self):\n",
    "        net = cv2.dnn.readNet(self.weights_file, self.config_file)\n",
    "\n",
    "        return net\n",
    "\n",
    "    def _get_bboxes_pixels(self, img):\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        Width = image.shape[1]\n",
    "        Height = image.shape[0]\n",
    "        scale = 0.00392\n",
    "\n",
    "        classes = None\n",
    "\n",
    "        \n",
    "        with open(classes_file, 'r') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        outs = self.net.forward(get_output_layers(self.net))\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.5\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "\n",
    "        bboxes_with_confidence = []\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "\n",
    "            except:\n",
    "                i = i[0]\n",
    "                box = boxes[i]\n",
    "\n",
    "\n",
    "            x = box[0]\n",
    "            y = box[1]\n",
    "            w = box[2]\n",
    "            h = box[3]\n",
    "            \n",
    "            if x < 0:\n",
    "                x = 0\n",
    "            if y < 0:\n",
    "                y = 0\n",
    "            \n",
    "            bboxes_with_confidence.append(np.array((x, x+w, y, y+h, 100*confidences[i])))\n",
    "            \n",
    "        # follows the format of x0, x1, y0, y1, confidence\n",
    "        return np.array(bboxes_with_confidence).astype(int)\n",
    "    \n",
    "    def _bbox_pixels_to_gps(self, bboxes, gps_corners, img_dim):\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = gps_corners\n",
    "        right_vec = (top_right_gps - top_left_gps) / img_dim[1]\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / img_dim[0]\n",
    "\n",
    "        transformation = np.array([[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]])\n",
    "\n",
    "        def transform(bbox):\n",
    "            return transformation @ bbox + top_left_gps\n",
    "            \n",
    "        return np.array([transform(bbox) for bbox in bboxes])\n",
    "    \n",
    "    def _convert_bbox_to_radial_representation(self, bboxes):\n",
    "        \"\"\"\n",
    "            Given a bbox in the format of x0, x1, y0, y1, confidence.\n",
    "            Returns a bbox in the format of x, y, r, confidence\n",
    "        \"\"\"\n",
    "\n",
    "        radii = np.sqrt((bboxes[:, 1] - bboxes[:, 0]) ** 2 + (bboxes[:, 3] - bboxes[:, 2]) ** 2)\n",
    "\n",
    "        return np.array([\n",
    "            (bboxes[:, 0] + bboxes[:, 1]) / 2,\n",
    "            (bboxes[:, 2] + bboxes[:, 3]) / 2,\n",
    "            radii,\n",
    "            bboxes[:, 4]\n",
    "        ]).T\n",
    "\n",
    "    def run(self, img):\n",
    "        bboxes_pixels = self._get_bboxes_pixels(img)\n",
    "        \n",
    "        return bboxes_pixels  # remove the pixels bboxes later\n",
    "    \n",
    "\n",
    "class MavlinkInterfaceLayer:\n",
    "    def __init__(self, protos_path=\"protos\"):\n",
    "        self.protos_path = protos_path\n",
    "        self.channel = grpc.insecure_channel(\"localhost:50051\")\n",
    "        self.stub = messaging_pb2_grpc.MessagingServiceStub(self.channel)\n",
    "        pass\n",
    "\n",
    "    def run(self, bboxes):\n",
    "        if len(bboxes) == 0:\n",
    "            return\n",
    "\n",
    "        print(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/RT-Flight/testing/RT-env/lib/python3.8/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (111695860 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29.7939 -81.9602 822.     876.    \n",
      " 30.3287 -81.2811 881.     928.    \n",
      " 29.5809 -82.2384 822.     875.    \n",
      " 30.1157 -81.5538 883.     927.    \n",
      " 29.9026 -81.8211 884.     926.    \n",
      " 29.4266 -82.492  829.     880.    \n",
      " 29.6874 -82.0857 886.     924.    \n",
      " 29.4657 -82.3475 881.     929.    \n",
      " 31.4809 -79.8902 770.     851.    \n",
      " 31.3483 -80.0293 691.     774.    \n",
      " 31.2266 -80.1929 604.     698.    \n",
      " 31.1026 -80.3511 526.     619.    \n",
      " 30.8853 -80.6211 904.     968.    \n",
      " 30.9766 -80.5093 449.     540.    \n",
      " 30.757  -80.7793 824.     890.    \n",
      " 30.8526 -80.6702 374.     462.    \n",
      " 30.6266 -80.9347 747.     812.    \n",
      " 30.7287 -80.8311 298.     381.    \n",
      " 30.5005 -81.0902 666.     735.    \n",
      " 30.6005 -80.9947 222.     304.    \n",
      " 30.37   -81.2457 588.     659.    \n",
      " 30.4744 -81.1502 144.     223.    \n",
      " 30.2418 -81.3984 505.     587.    \n",
      " 30.3505 -81.3111  65.     148.    \n",
      " 30.1113 -81.5593 428.     507.    \n",
      " 31.5439 -79.9011 818.     894.    \n",
      " 30.2222 -81.4584   0.      68.    \n",
      " 31.4113 -79.9311 742.     820.    \n",
      " 29.9896 -81.7229 352.     428.    \n",
      " 31.2831 -80.1002 664.     743.    \n",
      " 29.8657 -81.8811 276.     348.    \n",
      " 30.9787 -80.5502 381.     447.    \n",
      " 31.1613 -80.2584 588.     664.    \n",
      " 31.3874 -79.9938 607.     684.    \n",
      " 29.7396 -82.042  199.     271.    \n",
      " 29.4266 -82.582  107.     140.    \n",
      " 31.0331 -80.4193 509.     589.    \n",
      " 31.2635 -80.1575 531.     606.    \n",
      " 29.6113 -82.1975 119.     196.    \n",
      " 31.5418 -79.9011 680.     757.    \n",
      " 30.7266 -80.8666 229.     292.    \n",
      " 30.9679 -80.5938 933.     973.    \n",
      " 30.9092 -80.5747 433.     506.    \n",
      " 31.1374 -80.3157 453.     528.    \n",
      " 29.4853 -82.3557  42.     119.    \n",
      " 30.8461 -80.7493 851.     896.    \n"
     ]
    }
   ],
   "source": [
    "img_layer = ImageProcessingLayer(mock_wait_time=1)\n",
    "\n",
    "\n",
    "weights_file = \"/home/matt/RT-Flight/yolo-test/yolov3-aerial.weights\"\n",
    "classes_file = \"/home/matt/RT-Flight/yolo-test/aerial-darknet/data/aerial.names\"\n",
    "config_file = \"/home/matt/RT-Flight/yolo-test/aerial-darknet/cfg/yolov3-aerial.cfg\"\n",
    "\n",
    "obj_layer = OpenCVObjectDetectionLayer(config_file=config_file, weights_file=weights_file, classes_file=classes_file, device='cpu')\n",
    "# mav_layer = MavlinkInterfaceLayer()\n",
    "\n",
    "lat_center = 29.643946\n",
    "lon_center = -82.355659\n",
    "\n",
    "lat_mile = 0.0144927536231884\n",
    "lon_mile = 0.0181818181818182\n",
    "lat_min = lat_center - (15 * lat_mile)\n",
    "lat_max = lat_center + (15 * lat_mile)\n",
    "lon_min = lon_center - (15 * lon_mile)\n",
    "lon_max = lon_center + (15 * lon_mile)\n",
    "\n",
    "for img in img_layer.run():\n",
    "    bboxes = obj_layer.run(img)\n",
    "#     mav_layer.run(bboxes)\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        bbox = bbox.astype(float)\n",
    "        bbox[0] = float(float(bbox[0]) / 200 * ( lat_max - lat_min ) + lat_min)\n",
    "        bbox[1] = float(float(bbox[1]) / 200 * ( lon_max - lon_min ) + lon_min)\n",
    "        output = str(bbox[:4])[1:-1]\n",
    "        print(output)\n",
    "        \n",
    "#         response = mav_layer.stub.SendData(messaging_pb2.DataRequest(data=output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
