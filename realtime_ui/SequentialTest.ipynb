{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d37ce049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "sys.path.append(\"./protos\")\n",
    "\n",
    "import grpc\n",
    "import messaging_pb2\n",
    "import messaging_pb2_grpc\n",
    "\n",
    "class ObjectDetectionLayer:\n",
    "    def __init__(\n",
    "        self, weights_file=None, classes_file=None, config_file=None, min_confidence=0.3\n",
    "    ):\n",
    "        self.weights_file = weights_file\n",
    "        self.config_file = config_file\n",
    "        self.classes_file = classes_file\n",
    "\n",
    "        self.net = self._load_model()\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "        self.classes = [\"car\", \"truck\", \"bus\", \"minibus\", \"cyclist\"]\n",
    "\n",
    "    def _load_model(self):\n",
    "        return cv2.dnn.readNet(self.weights_file, self.config_file)\n",
    "\n",
    "    def _get_output_layers(self, net):\n",
    "        layer_names = net.getLayerNames()\n",
    "        try:\n",
    "            output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        except:\n",
    "            output_layers = [\n",
    "                layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()\n",
    "            ]\n",
    "\n",
    "        return output_layers\n",
    "\n",
    "    def _get_bboxes_pixels(self, img):\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        Height, Width = image.shape[:2]\n",
    "        scale = 0.00392\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image, scale, (416, 416), (0, 0, 0), True, crop=False\n",
    "        )\n",
    "\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        outs = self.net.forward(self._get_output_layers(self.net))\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.5\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > self.min_confidence:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        bboxes_with_confidence = []\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "            except Exception:\n",
    "                box = boxes[i[0]]\n",
    "\n",
    "            x, y, w, h = [max(v, 0) for v in box[:4]]  # model outputs can be negative\n",
    "\n",
    "            bboxes_with_confidence.append(\n",
    "                np.array((x, x + w, y, y + h, 100 * confidences[i]))\n",
    "            )\n",
    "\n",
    "        # follows the format of x0, x1, y0, y1, confidence\n",
    "        return np.array(bboxes_with_confidence).astype(int)\n",
    "\n",
    "    def _bbox_pixels_to_gps(self, bboxes, gps_corners, img_dim):\n",
    "        top_left_gps, top_right_gps, bot_left_gps, bot_right_gps = gps_corners\n",
    "        right_vec = (top_right_gps - top_left_gps) / img_dim[1]\n",
    "        bot_vec = (bot_left_gps - top_left_gps) / img_dim[0]\n",
    "\n",
    "        transformation = np.array(\n",
    "            [[right_vec[0], bot_vec[0]], [right_vec[1], bot_vec[1]]]\n",
    "        )\n",
    "\n",
    "        def transform(bbox):\n",
    "            return transformation @ bbox + top_left_gps\n",
    "\n",
    "        return np.array([(*transform(bbox[:2]), *bbox[2:4]) for bbox in bboxes])\n",
    "\n",
    "    # Be careful using this radius. Pixel distance does not convert to latitude and longitude in the same way\n",
    "    def _convert_bbox_to_radial_representation(self, bboxes):\n",
    "        \"\"\"\n",
    "        Given a bbox in the format of x0, x1, y0, y1, confidence.\n",
    "        Returns a bbox in the format of x, y, r, confidence\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Scale by some factor (function of altitude) to convert pixels to meters\n",
    "        dx = bboxes[:, 1] - bboxes[:, 0]\n",
    "        dy = bboxes[:, 3] - bboxes[:, 2]\n",
    "        radii = np.sqrt(dx**2 + dy**2) / 2\n",
    "\n",
    "        return np.array(\n",
    "            [\n",
    "                (bboxes[:, 0] + bboxes[:, 1]) / 2,\n",
    "                (bboxes[:, 2] + bboxes[:, 3]) / 2,\n",
    "                radii,\n",
    "                bboxes[:, 4],\n",
    "            ]\n",
    "        ).T\n",
    "\n",
    "    def run(self, img, gps_sample_corners):\n",
    "        bboxes_pixels = self._get_bboxes_pixels(img)\n",
    "\n",
    "        if len(bboxes_pixels) == 0:\n",
    "            return [], []\n",
    "\n",
    "        bboxes_radial_pixels = self._convert_bbox_to_radial_representation(\n",
    "            bboxes_pixels\n",
    "        )\n",
    "        bboxes_radial_gps = self._bbox_pixels_to_gps(\n",
    "            bboxes_radial_pixels, gps_sample_corners, img.shape\n",
    "        )\n",
    "\n",
    "        return bboxes_radial_gps, bboxes_pixels  # remove the pixels bboxes later\n",
    "\n",
    "\n",
    "class MavlinkInterfaceLayer:\n",
    "    def __init__(self, protos_path=\"protos\"):\n",
    "        self.protos_path = protos_path\n",
    "        self.channel = grpc.insecure_channel(\"localhost:50051\")\n",
    "        self.stub = messaging_pb2_grpc.MessagingServiceStub(self.channel)\n",
    "\n",
    "    def run(self, bboxes):\n",
    "        if len(bboxes) == 0:\n",
    "            return\n",
    "\n",
    "        responses = []\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            encoded_bbox = str(bbox)[1:-1] # remove the brackets\n",
    "            response = self.stub.SendData(messaging_pb2.DataRequest(data=encoded_bbox))\n",
    "            responses.append(response)\n",
    "\n",
    "        return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d8d0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy\n",
    "import geopy.distance\n",
    "\n",
    "def _destination_point(start_lat, start_lon, bearing, distance):\n",
    "        start_point = geopy.Point(start_lat, start_lon)\n",
    "        distance = geopy.distance.distance(meters=distance)\n",
    "        destination_point = distance.destination(point=start_point, bearing=bearing)\n",
    "        return destination_point.latitude, destination_point.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d0ea440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = sorted(os.listdir(\"../data_ignore/sequential_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b80ff215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0199.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0200.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0201.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0202.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0203.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0204.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0205.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0206.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0207.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0208.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0209.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0210.JPG\n",
      "calculating GPS corners for image: ../data_ignore/sequential_data/DJI_0211.JPG\n"
     ]
    }
   ],
   "source": [
    "import exiftool\n",
    "\n",
    "img_layer_replacement = []\n",
    "directory_path = \"../data_ignore/sequential_data/\"\n",
    "\n",
    "\n",
    "for image_name in filenames[197:210]:\n",
    "    \n",
    "    image_path = directory_path + image_name\n",
    "    print(f\"calculating GPS corners for image: {image_path}\")\n",
    "    image = np.asarray(Image.open(image_path))[:, :, :3]\n",
    "    with exiftool.ExifToolHelper() as et:\n",
    "        metadata = et.get_metadata(image_path)[0]\n",
    "\n",
    "    yaw = metadata[\"XMP:GimbalYawDegree\"]\n",
    "    if isinstance(yaw, str):\n",
    "        yaw = float(yaw[1:])\n",
    "\n",
    "    latitude = metadata[\"EXIF:GPSLatitude\"]\n",
    "    longitude = metadata[\"EXIF:GPSLongitude\"]\n",
    "\n",
    "    altitude = metadata[\"XMP:RelativeAltitude\"] # meters\n",
    "    if isinstance(altitude, str):\n",
    "        altitude = float(altitude[1:])\n",
    "\n",
    "    radians = math.radians(69.4)\n",
    "    base = 2*altitude*math.tan(radians/2)\n",
    "    width = base\n",
    "    height = base * 3/4\n",
    "\n",
    "    sequential_image_height = 3000\n",
    "    sequential_image_width = 4000\n",
    "\n",
    "    meters_per_pixel = width / sequential_image_width\n",
    "\n",
    "    si_top_gps = _destination_point(latitude, longitude, yaw, height/2)\n",
    "    si_top_right_gps = _destination_point(si_top_gps[0], si_top_gps[1], yaw+90, width/2)\n",
    "    si_top_left_gps = _destination_point(si_top_gps[0], si_top_gps[1], yaw-90, width/2)\n",
    "\n",
    "    si_bot_gps = _destination_point(latitude, longitude, yaw+180, height/2)\n",
    "    si_bot_right_gps = _destination_point(si_bot_gps[0], si_bot_gps[1], yaw+90, width/2)\n",
    "    si_bot_left_gps = _destination_point(si_bot_gps[0], si_bot_gps[1], yaw-90, width/2)\n",
    "\n",
    "    image_corner_gps = (si_top_left_gps, si_top_right_gps, si_bot_left_gps, si_bot_right_gps)\n",
    "\n",
    "    img_layer_replacement.append((image, image_corner_gps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1100af05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[882 936  15  84  61]]\n",
      "[[ 176  310  706  877   99]\n",
      " [2297 2395   15   71   63]]\n",
      "[[ 197  303 1136 1328   96]\n",
      " [ 616  748  255  414   86]\n",
      " [ 638  700   61  157   77]\n",
      " [ 334  506  823 1097   75]]\n",
      "[[ 807  908  307  457   98]\n",
      " [ 981 1090  109  227   62]]\n",
      "[[ 877  996 2652 2850   96]\n",
      " [1321 1460   25  179   88]\n",
      " [1514 1585    0   88   52]]\n",
      "[[1045 1166 2414 2637   96]]\n",
      "[[2183 2308  104  306   99]\n",
      " [1906 2021  754  932   98]\n",
      " [1752 1846 1171 1350   94]\n",
      " [1843 1971 1218 1389   82]\n",
      " [2028 2116 2600 2677   70]]\n",
      "[[1652 1771 2352 2547   98]\n",
      " [2117 2222 1310 1467   89]\n",
      " [1546 1616 2322 2414   76]]\n",
      "[[2701 2751  388  496   90]]\n",
      "[[2537 2649 1888 2058   96]\n",
      " [2926 2993  538  629   94]\n",
      " [3728 3857  783  974   73]]\n",
      "[[2624 2739 2216 2377   95]\n",
      " [3275 3386 1035 1249   90]\n",
      " [2466 2591 2688 2862   78]\n",
      " [3255 3331  557  655   52]]\n"
     ]
    }
   ],
   "source": [
    "weights_file = \"../yolo/yolov3-aerial.weights\"\n",
    "classes_file = \"../yolo/aerial.names\"\n",
    "config_file = \"../yolo/yolov3-aerial.cfg\"\n",
    "\n",
    "obj_layer = ObjectDetectionLayer(\n",
    "    config_file=config_file, weights_file=weights_file, classes_file=classes_file\n",
    ")\n",
    "\n",
    "mav_layer = MavlinkInterfaceLayer()\n",
    "\n",
    "for img, img_corner_gps in img_layer_replacement:\n",
    "    img_corner_gps = np.array(img_corner_gps)\n",
    "    bboxes_gps, bboxes_pixels = obj_layer.run(img, img_corner_gps)\n",
    "\n",
    "    for bbox_gps in bboxes_gps:\n",
    "        bbox_gps[2] = bbox_gps[2] * meters_per_pixel\n",
    "\n",
    "    responses = mav_layer.run(bboxes_gps)\n",
    "    \n",
    "    if len(bboxes_gps) != 0 and len(responses) == 0:\n",
    "        print(\"No responses from MAVLink\")\n",
    "\n",
    "    if responses: \n",
    "        print(bboxes_pixels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RT-env",
   "language": "python",
   "name": "rt-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
