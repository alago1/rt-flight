{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allanlago/anaconda3/envs/rt-flight/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "\n",
    "mmcv.collect_env()\n",
    "\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmdet.apis import inference_detector\n",
    "from mmrotate.models import build_detector\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "import grpc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "class ImageProcessingLayer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        mock=True,\n",
    "        mock_image_path=None,\n",
    "        mock_num_samples=10,\n",
    "        mock_wait_time=1,\n",
    "    ):\n",
    "        self.mock = mock\n",
    "\n",
    "        if not mock:\n",
    "            return\n",
    "\n",
    "        self.mock_wait_time = mock_wait_time\n",
    "\n",
    "        if mock_image_path is None:\n",
    "            mock_image_path = \"data/demo.jpg\"\n",
    "\n",
    "        self._mock_img_full = np.asarray(Image.open(mock_image_path))\n",
    "        self._output_dim = (200, 200)\n",
    "        diag_len = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "        self._gcps_pixels = self._generate_random_gcps(\n",
    "            self._mock_img_full, mock_num_samples, padding=(diag_len, diag_len)\n",
    "        )\n",
    "\n",
    "        # maybe convert from pixels to lat/lon here\n",
    "\n",
    "        self._path_pixels = self._build_path_pixels(self._gcps_pixels)\n",
    "\n",
    "    def _generate_random_gcps(self, img, num_samples, padding=(0, 0)):\n",
    "        return np.random.randint(\n",
    "            padding,\n",
    "            high=(img.shape[0] - padding[0], img.shape[1] - padding[1]),\n",
    "            size=(num_samples, 2),\n",
    "        )\n",
    "\n",
    "    def _build_path_pixels(self, gcps):\n",
    "        delta = np.diff(gcps, axis=0)\n",
    "        directions = delta / np.linalg.norm(delta, axis=1).reshape(-1, 1)\n",
    "        angles = np.arctan2(directions.T[1], directions.T[0]) * 180 / np.pi\n",
    "        delta_angles = np.append(np.diff(angles), 0)\n",
    "\n",
    "        path = []\n",
    "\n",
    "        for t1, t2, angle, delta_angle in zip(gcps, gcps[1:], angles, delta_angles):\n",
    "            steps = np.linalg.norm(t2 - t1) / 90\n",
    "            line = np.linspace(t1, t2, steps.astype(\"uint32\"), dtype=\"uint32\")\n",
    "            path.extend([np.array([x, y, angle]) for x, y in line])\n",
    "\n",
    "            if delta_angle == 0:\n",
    "                continue\n",
    "\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "\n",
    "            interpolated_angles = np.linspace(angle, angle + delta_angle, 3)\n",
    "            path.extend(\n",
    "                [\n",
    "                    np.array([line[-1][0], line[-1][1], theta])\n",
    "                    for theta in interpolated_angles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return path\n",
    "\n",
    "    def _next_image(self):\n",
    "        if self.mock_wait_time > 0:\n",
    "            time.sleep(self.mock_wait_time)\n",
    "\n",
    "        sample_diag = np.sqrt(self._output_dim[0] ** 2 + self._output_dim[1] ** 2)\n",
    "\n",
    "        for x, y, theta in self._path_pixels:\n",
    "            sample = self._crop_around(\n",
    "                self._mock_img_full, (y, x), (sample_diag, sample_diag)\n",
    "            )\n",
    "            rotated_img = self._center_crop(\n",
    "                rotate(sample, -theta, reshape=False), self._output_dim\n",
    "            )\n",
    "            yield rotated_img\n",
    "\n",
    "    def _crop_around(self, img, center, dim):\n",
    "        dim = np.array(dim).astype(\"uint32\")\n",
    "        x = int(center[1] - dim[1] // 2)\n",
    "        y = int(center[0] - dim[0] // 2)\n",
    "        return img[y : y + dim[0], x : x + dim[1]]\n",
    "\n",
    "    def _center_crop(self, img, dim):\n",
    "        return img[\n",
    "            img.shape[0] // 2 - dim[0] // 2 : img.shape[0] // 2 + dim[0] // 2,\n",
    "            img.shape[1] // 2 - dim[1] // 2 : img.shape[1] // 2 + dim[1] // 2,\n",
    "        ]\n",
    "\n",
    "    def run(self, img=None):\n",
    "        if not self.mock:\n",
    "            assert img is not None, \"Image cannot be None\"\n",
    "            return img\n",
    "\n",
    "        return self._next_image()\n",
    "\n",
    "\n",
    "class ObjectDetectionLayer:\n",
    "    def __init__(\n",
    "        self, config_file=None, checkpoint_file=None, device=\"cuda\", min_confidence=0.3\n",
    "    ):\n",
    "        if config_file is None:\n",
    "            config_file = \"examples/oriented_rcnn_r50_fpn_1x_dota_le90.py\"\n",
    "        if checkpoint_file is None:\n",
    "            checkpoint_file = \"examples/oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth\"\n",
    "\n",
    "        self.config_file = config_file\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.device = device\n",
    "\n",
    "        self.model = self._load_model()\n",
    "        self.min_confidence = min_confidence\n",
    "\n",
    "    def _load_model(self):\n",
    "        config = mmcv.Config.fromfile(self.config_file)\n",
    "        config.model.pretrained = None\n",
    "\n",
    "        model = build_detector(config.model)\n",
    "        checkpoint = load_checkpoint(\n",
    "            model, self.checkpoint_file, map_location=self.device\n",
    "        )\n",
    "\n",
    "        model.CLASSES = checkpoint[\"meta\"][\"CLASSES\"]\n",
    "        model.cfg = config\n",
    "        model.to(self.device)\n",
    "        model = model.eval()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def _get_bboxes_pixels(self, img):\n",
    "        padded_img = np.zeros((max(img.shape[0], 1024), max(img.shape[1], 1024), 3))\n",
    "        padded_img[: img.shape[0], : img.shape[1]] = img\n",
    "\n",
    "        vehicle_classes = [\n",
    "            i for i, c in enumerate(self.model.CLASSES) if \"vehicle\" in c\n",
    "        ]\n",
    "\n",
    "        inference = inference_detector(self.model, padded_img)\n",
    "        bboxes = [inference[index] for index in vehicle_classes]\n",
    "\n",
    "        bboxes = np.concatenate(bboxes, axis=0)\n",
    "        bboxes = bboxes[bboxes[:, 5] > self.min_confidence]\n",
    "\n",
    "        # the bboxes are in a weird polygonal format, so we convert them to rectangles\n",
    "        rect_bboxes = (\n",
    "            np.array(\n",
    "                [\n",
    "                    bboxes[:, 1] - bboxes[:, 2] // 2,\n",
    "                    bboxes[:, 1] + bboxes[:, 2] // 2,\n",
    "                    bboxes[:, 0] - bboxes[:, 2] // 2,\n",
    "                    bboxes[:, 0] + bboxes[:, 3],\n",
    "                    100 * bboxes[:, -1],  # confidence score\n",
    "                ]\n",
    "            )\n",
    "            .astype(int)\n",
    "            .T\n",
    "        )\n",
    "\n",
    "        # follows the format of x0, x1, y0, y1, confidence\n",
    "        return rect_bboxes\n",
    "\n",
    "    def run(self, img):\n",
    "        result = self._get_bboxes_pixels(img)\n",
    "\n",
    "        # convert pixels to lat/lon here\n",
    "        return result\n",
    "\n",
    "\n",
    "class MavlinkInterfaceLayer:\n",
    "    def __init__(self, protos_path=\"pipelined_grpc/protos\"):\n",
    "        self.protos_path = protos_path\n",
    "        \n",
    "        sys.path.append(os.path.join(os.getcwd(), self.protos_path))\n",
    "        import messaging_pb2 as messaging_pb2\n",
    "        import messaging_pb2_grpc as messaging_pb2_grpc\n",
    "\n",
    "        self.messaging_pb2 = messaging_pb2\n",
    "        \n",
    "        self.channel = grpc.insecure_channel(\"localhost:54051\")\n",
    "        self.stub = messaging_pb2_grpc.MessagingServiceStub(self.channel)\n",
    "\n",
    "    def run(self, bboxes):\n",
    "        if len(bboxes) == 0:\n",
    "            return\n",
    "\n",
    "        print(bboxes)\n",
    "\n",
    "        message = self.messaging_pb2.ProcessedDataRequest(request=str(bboxes))\n",
    "        response = self.stub.RequestProcessedData(message)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allanlago/Documents/jupyter-notebooks/rt-flight/examples/mmdetection/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: examples/oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allanlago/Documents/jupyter-notebooks/rt-flight/examples/mmdetection/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[149 163  58  71  79]\n",
      " [157 169  57  68  77]\n",
      " [172 186  51  62  63]\n",
      " [167 181  52  64  53]\n",
      " [161 175  54  66  49]\n",
      " [179 191  49  61  49]\n",
      " [183 197  47  59  45]]\n",
      "\n",
      "[[149 163  58  71  79]\n",
      " [157 169  57  68  77]\n",
      " [172 186  51  62  63]\n",
      " [167 181  52  64  53]\n",
      " [161 175  54  66  49]\n",
      " [179 191  49  61  49]\n",
      " [183 197  47  59  45]]\n",
      "\n",
      "[[72 86 29 42 77]\n",
      " [71 85 22 35 47]]\n",
      "\n",
      "[[ 28  40  98 110  85]\n",
      " [ 21  33  97 109  77]\n",
      " [ 15  27  96 107  64]\n",
      " [  8  22  94 106  62]\n",
      " [  3  17  93 105  58]\n",
      " [ 62  76 103 115  32]\n",
      " [ -3  10  92 104  31]]\n",
      "\n",
      "[[ 28  40  98 110  85]\n",
      " [ 21  33  97 109  77]\n",
      " [ 15  27  96 107  64]\n",
      " [  8  22  94 106  62]\n",
      " [  3  17  93 105  58]\n",
      " [ 62  76 103 115  32]\n",
      " [ -3  10  92 104  31]]\n",
      "\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[  3  15 112 123  60]\n",
      " [ 17  31 104 116  60]\n",
      " [ 13  25 107 119  59]\n",
      " [  6  20 109 121  57]\n",
      " [ 24  36 102 113  55]\n",
      " [ 28  42 100 112  46]\n",
      " [ 46  58  93 104  43]\n",
      " [ -4   9 114 126  31]\n",
      " [ 50  64  90 102  31]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_layer = ImageProcessingLayer(mock_wait_time=1)\n",
    "obj_layer = ObjectDetectionLayer()\n",
    "mav_layer = MavlinkInterfaceLayer()\n",
    "\n",
    "for img in img_layer.run():\n",
    "    bboxes = obj_layer.run(img)\n",
    "    response = mav_layer.run(bboxes)\n",
    "    if len(bboxes):\n",
    "        print(response)\n",
    "\n",
    "    # for bbox in bboxes:\n",
    "    #     plt.imshow(img[bbox[0]:bbox[1], bbox[2]:bbox[3]])\n",
    "    #     plt.title(\"Confidence: {}\".format(bbox[4]))\n",
    "    #     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rt-flight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
